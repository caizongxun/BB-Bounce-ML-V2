#!/usr/bin/env python3
"""
BB åå½ˆ V2 æ¨¡å‹è¨“ç·´å™¨

æ ¸å¿ƒç†è«–ï¼š
- ç„¡æ•ˆåå½ˆï¼šBB é€šé“å‘å¤–æ“´å¼µï¼ˆæ³¢å‹•ç‡ä¸Šå‡ï¼‰â†’ å¸‚å ´æ··äº‚ â†’ åå½ˆå¤±æ•—
- æœ‰æ•ˆåå½ˆï¼šBB é€šé“å‘å…§ç¸®å°ï¼ˆæ³¢å‹•ç‡ä¸‹é™ï¼‰â†’ å¸‚å ´ç§©åºæ¢å¾© â†’ åå½ˆæˆåŠŸ

æ–°å¢ç‰¹å¾µï¼š
1. bb_width_change - BB å¯¬åº¦è®ŠåŒ–ç‡ï¼ˆæœ€é‡è¦ï¼‰
2. bb_width_percentile - BB å¯¬åº¦ç›¸å°æ­·å²ä½ç½®
3. std_change - æ¨™æº–å·®è®ŠåŒ–ç‡
4. upper_lower_distance_change - ä¸Šä¸‹è»Œé è¿‘é€Ÿåº¦
5. width_acceleration - BB å¯¬åº¦è®ŠåŒ–åŠ é€Ÿåº¦
"""

import pandas as pd
import numpy as np
from pathlib import Path
import joblib
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    classification_report, confusion_matrix, accuracy_score,
    precision_score, recall_score, f1_score, roc_auc_score
)
from xgboost import XGBClassifier
import warnings

warnings.filterwarnings('ignore')

from data_loader import CryptoDataLoader

class BBContractionFeatureExtractor:
    """æå– BB é€šé“æ”¶ç¸®ç›¸é—œç‰¹å¾µ"""
    
    @staticmethod
    def calculate_bb_bands(closes, period=20, std_dev=2):
        """è¨ˆç®—å¸ƒæ—é€šé“"""
        sma = np.mean(closes[-period:])
        std = np.std(closes[-period:])
        upper = sma + std_dev * std
        lower = sma - std_dev * std
        width = upper - lower
        return upper, sma, lower, width, std
    
    @staticmethod
    def create_features(df: pd.DataFrame, lookahead=5) -> pd.DataFrame:
        """
        å»ºç«‹ç‰¹å¾µï¼Œé‡é»æ”¾åœ¨ BB é€šé“æ”¶ç¸®ç‰¹å¾µ
        """
        df = df.copy()
        close_col = 'close' if 'close' in df.columns else 'Close'
        
        # è¨ˆç®— BB å¸¶ç‹€
        bb_period = 20
        uppers = []
        middles = []
        lowers = []
        widths = []
        stds = []
        
        for i in range(len(df)):
            if i < bb_period:
                uppers.append(np.nan)
                middles.append(np.nan)
                lowers.append(np.nan)
                widths.append(np.nan)
                stds.append(np.nan)
            else:
                closes_window = df[close_col].iloc[i-bb_period:i].values
                upper, middle, lower, width, std = BBContractionFeatureExtractor.calculate_bb_bands(closes_window)
                uppers.append(upper)
                middles.append(middle)
                lowers.append(lower)
                widths.append(width)
                stds.append(std)
        
        df['bb_upper'] = uppers
        df['bb_middle'] = middles
        df['bb_lower'] = lowers
        df['bb_width'] = widths
        df['bb_std'] = stds
        
        # ========================================
        # ç‰¹å¾µ 1ï¼šBB å¯¬åº¦è®ŠåŒ–
        # ========================================
        
        # çŸ­æœŸå¯¬åº¦è®ŠåŒ–
        df['bb_width_change_1bar'] = df['bb_width'].pct_change(1)
        df['bb_width_change_2bar'] = df['bb_width'].pct_change(2)
        df['bb_width_change_3bar'] = df['bb_width'].pct_change(3)
        df['bb_width_change_5bar'] = df['bb_width'].pct_change(5)
        
        # BB å¯¬åº¦åœ¨æ­·å²ä¸­çš„ç›¸å°ä½ç½®
        df['bb_width_percentile'] = df['bb_width'].rolling(window=20).apply(
            lambda x: (x.iloc[-1] - x.min()) / (x.max() - x.min() + 1e-8),
            raw=False
        )
        
        # æ¨™æº–å·®è®ŠåŒ–
        df['std_change'] = df['bb_std'].pct_change()
        df['std_change_3bar'] = df['bb_std'].pct_change(3)
        
        # ä¸Šä¸‹è»Œé è¿‘é€Ÿåº¦
        df['bb_distance'] = df['bb_upper'] - df['bb_lower']
        df['bb_distance_change'] = df['bb_distance'].pct_change()
        
        # BB å¯¬åº¦è®ŠåŒ–åŠ é€Ÿåº¦
        df['bb_width_acceleration'] = df['bb_width_change_1bar'].diff()
        
        # ========================================
        # å…¶ä»–ç‰¹å¾µ
        # ========================================
        
        # RSI
        delta = df[close_col].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / (loss + 1e-8)
        df['rsi_14'] = 100 - (100 / (1 + rs))
        
        # åƒ¹æ ¼ç›¸å° BB ä½ç½®
        df['price_bb_position'] = (df[close_col] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'] + 1e-8)
        
        # æˆäº¤é‡æ¯”
        if 'volume' in df.columns:
            df['volume_ratio'] = df['volume'] / df['volume'].rolling(window=20).mean()
        else:
            df['volume_ratio'] = 1.0
        
        # æ³¢å‹•ç‡æ¯”
        df['historical_vol'] = df[close_col].pct_change().rolling(window=20).std()
        df['vol_ratio'] = df['bb_std'] / (df['bb_std'].rolling(window=40).mean() + 1e-8)
        
        # åƒ¹æ ¼å‹•é‡
        df['momentum_5'] = df[close_col].pct_change(5)
        df['momentum_10'] = df[close_col].pct_change(10)
        
        # å¡«å…… NaN
        df = df.fillna(method='bfill').fillna(method='ffill')
        
        # ========================================
        # ç”Ÿæˆæ¨™ç±¤ï¼ˆæ”¹é€²ç‰ˆï¼‰
        # ========================================
        
        df['label_bounce_valid'] = -1  # é è¨­ç‚º -1ï¼ˆå¿½ç•¥ï¼‰
        
        for i in range(len(df) - lookahead):
            # æ¢ä»¶ 1ï¼šç•¶å‰ K æ£’è§¸åŠæˆ–æ¥è¿‘ä¸‹è»Œ
            price_to_lower = (df[close_col].iloc[i] - df['bb_lower'].iloc[i]) / (df['bb_width'].iloc[i] + 1e-8)
            is_near_lower = price_to_lower < 0.20  # åœ¨ä¸‹è»Œé™„è¿‘ 20% å…§
            
            if not is_near_lower:
                continue
            
            # ========================================
            # æ ¸å¿ƒé‚è¼¯ï¼šæ¯”è¼ƒå‰å¾Œçš„ BB å¯¬åº¦è®ŠåŒ–
            # ========================================
            
            # éå» 3 æ ¹ K æ£’çš„å¹³å‡ BB å¯¬åº¦
            past_widths = df['bb_width'].iloc[max(0, i-3):i].values
            past_avg_width = np.mean(past_widths) if len(past_widths) > 0 else 0
            
            # æ¥ä¸‹ä¾† lookahead æ ¹ K æ£’çš„å¹³å‡ BB å¯¬åº¦
            future_widths = df['bb_width'].iloc[i:i+lookahead].values
            future_avg_width = np.mean(future_widths) if len(future_widths) > 0 else 0
            
            if past_avg_width == 0:
                continue
            
            # BB å¯¬åº¦è®ŠåŒ–æ¯”ç‡
            width_change_ratio = (future_avg_width - past_avg_width) / past_avg_width
            
            # æ¥ä¸‹ä¾† lookahead æ ¹ K æ£’çš„åƒ¹æ ¼è®ŠåŒ–
            future_prices = df[close_col].iloc[i:i+lookahead].values
            future_price_change = (future_prices[-1] - future_prices[0]) / (future_prices[0] + 1e-8)
            
            # ========================================
            # æ”¹é€²çš„æ¨™ç±¤é‚è¼¯ï¼ˆç›¸å°æ¯”è¼ƒè€Œéçµ•å°é–¾å€¼ï¼‰
            # ========================================
            
            # æƒ…æ³ 1ï¼šBB å¯¬åº¦æ”¶ç¸® + åƒ¹æ ¼ä¸Šå‡ = æœ‰æ•ˆåå½ˆï¼ˆæœ€ç†æƒ³ï¼‰
            if width_change_ratio < -0.10 and future_price_change > 0.003:
                df.loc[i, 'label_bounce_valid'] = 1
            
            # æƒ…æ³ 2ï¼šBB å¯¬åº¦æ”¶ç¸® + åƒ¹æ ¼ç©©å®š = æœ‰æ•ˆåå½ˆï¼ˆæ¬¡ç†æƒ³ï¼‰
            elif width_change_ratio < -0.05 and -0.005 < future_price_change < 0.010:
                df.loc[i, 'label_bounce_valid'] = 1
            
            # æƒ…æ³ 3ï¼šBB å¯¬åº¦æ“´å¼µ + åƒ¹æ ¼ä¸‹è·Œ = ç„¡æ•ˆåå½ˆï¼ˆæœ€å·®ï¼‰
            elif width_change_ratio > 0.15 and future_price_change < -0.005:
                df.loc[i, 'label_bounce_valid'] = 0
            
            # æƒ…æ³ 4ï¼šBB å¯¬åº¦æ“´å¼µ + åƒ¹æ ¼æ··äº‚ = ç„¡æ•ˆåå½ˆï¼ˆæ¬¡å·®ï¼‰
            elif width_change_ratio > 0.05 and future_price_change < 0.002:
                df.loc[i, 'label_bounce_valid'] = 0
            
            # å…¶ä»–æƒ…æ³ï¼šä¸­æ€§ï¼Œå¿½ç•¥
            # (ä¿æŒ -1ï¼Œå¾Œé¢æœƒç¯©é¸æ‰)
        
        return df


class BBContractionModelTrainer:
    def __init__(self, output_dir='models'):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.models_dir = self.output_dir / 'bb_contraction_v2_models'
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        self.loader = CryptoDataLoader()
    
    def train_single_symbol(self, symbol: str, timeframe: str):
        """
        ç‚ºå–®å€‹å¹£ç¨® + æ™‚é–“æ¡†æ¶è¨“ç·´ BB æ”¶ç¸®æ¨¡å‹
        """
        separator = '=' * 70
        print(f'\n{separator}')
        print(f'è¨“ç·´ {symbol} {timeframe} - BB æ”¶ç¸® V2 æ¨¡å‹')
        print(f'{separator}')
        
        try:
            # 1. ä¸‹è¼‰æ•¸æ“š
            print(f'ä¸‹è¼‰ {symbol} {timeframe} æ•¸æ“š...')
            df = self.loader.download_symbol_data(symbol, timeframe)
            if df is None or len(df) < 100:
                print(f'âœ— {symbol} {timeframe} æ•¸æ“šä¸è¶³')
                return False
            
            # 2. ç‰¹å¾µå·¥ç¨‹
            print(f'æå– BB æ”¶ç¸®ç‰¹å¾µ...')
            extractor = BBContractionFeatureExtractor()
            df = extractor.create_features(df, lookahead=5)
            
            # 3. ç¯©é¸æœ‰æ•ˆæ¨™ç±¤ï¼ˆ-1 çš„è¡Œè¢«ä¸Ÿæ£„ï¼‰
            df_labeled = df[df['label_bounce_valid'] != -1].copy()
            
            if len(df_labeled) < 50:
                print(f'âœ— æœ‰æ•ˆæ¨™ç±¤æ¨£æœ¬éå°‘ï¼š{len(df_labeled)} å€‹')
                return False
            
            label_counts = df_labeled['label_bounce_valid'].value_counts()
            print(f'\næ¨™ç±¤åˆ†å¸ƒï¼š')
            print(f'  æœ‰æ•ˆåå½ˆ (1): {label_counts.get(1, 0)} å€‹ ({label_counts.get(1, 0)/len(df_labeled)*100:.1f}%)')
            print(f'  ç„¡æ•ˆåå½ˆ (0): {label_counts.get(0, 0)} å€‹ ({label_counts.get(0, 0)/len(df_labeled)*100:.1f}%)')
            
            if label_counts.get(1, 0) < 10 or label_counts.get(0, 0) < 10:
                print(f'âš ï¸ æŸé¡åˆ¥æ¨£æœ¬éå°‘ï¼Œè¨“ç·´å¯èƒ½ä¸ç©©å®š')
            
            # 4. é¸æ“‡ç‰¹å¾µ
            feature_cols = [
                # BB æ”¶ç¸®ç‰¹å¾µï¼ˆæœ€é‡è¦ï¼‰
                'bb_width_change_1bar', 'bb_width_change_2bar', 'bb_width_change_3bar', 'bb_width_change_5bar',
                'bb_width_percentile', 'std_change', 'std_change_3bar',
                'bb_distance_change', 'bb_width_acceleration',
                
                # å‹•é‡å’Œåƒ¹æ ¼ç‰¹å¾µ
                'rsi_14', 'price_bb_position', 'momentum_5', 'momentum_10',
                
                # æˆäº¤é‡å’Œæ³¢å‹•ç‡
                'volume_ratio', 'vol_ratio', 'historical_vol'
            ]
            
            X = df_labeled[feature_cols]
            y = df_labeled['label_bounce_valid']
            
            # ç§»é™¤ NaN
            mask = ~X.isna().any(axis=1)
            X = X[mask]
            y = y[mask]
            
            if len(X) < 30:
                print(f'âœ— æœ‰æ•ˆæ¨£æœ¬éå°‘ï¼š{len(X)} å€‹')
                return False
            
            print(f'\nç‰¹å¾µæ•¸ï¼š{len(feature_cols)}')
            print(f'æœ‰æ•ˆæ¨£æœ¬æ•¸ï¼š{len(X)}')
            print(f'é¡åˆ¥æ¯”ä¾‹ï¼š{y.value_counts().to_dict()}')
            
            # 5. åˆ†å‰²è¨“ç·´/æ¸¬è©¦é›†
            try:
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42, stratify=y
                )
            except:
                print(f'âš ï¸ æ¨£æœ¬ä¸è¶³ä»¥åˆ†å±¤æŠ½æ¨£ï¼Œä½¿ç”¨æ™®é€šåˆ†å‰²')
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42
                )
            
            # 6. æ¨™æº–åŒ–
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # 7. è¨“ç·´æ¨¡å‹
            print(f'\nè¨“ç·´ XGBoost åˆ†é¡å™¨...')
            model = XGBClassifier(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                eval_metric='logloss',
                verbosity=0,
                scale_pos_weight=len(y[y==0]) / len(y[y==1]) if len(y[y==1]) > 0 else 1  # è™•ç†é¡åˆ¥ä¸å¹³è¡¡
            )
            model.fit(X_train_scaled, y_train)
            
            # 8. è©•ä¼°
            y_pred = model.predict(X_test_scaled)
            y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
            
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, zero_division=0)
            recall = recall_score(y_test, y_pred, zero_division=0)
            f1 = f1_score(y_test, y_pred, zero_division=0)
            auc = roc_auc_score(y_test, y_pred_proba) if len(set(y_test)) > 1 else 0.5
            
            print(f'\næ¸¬è©¦é›†æ€§èƒ½ï¼š')
            print(f'  æº–ç¢ºç‡: {accuracy:.4f} ({accuracy*100:.2f}%)')
            print(f'  ç²¾æº–åº¦: {precision:.4f}')
            print(f'  å¬å›ç‡: {recall:.4f}')
            print(f'  F1 åˆ†æ•¸: {f1:.4f}')
            print(f'  AUC: {auc:.4f}')
            
            print(f'\næ··æ·†çŸ©é™£ï¼š')
            print(confusion_matrix(y_test, y_pred))
            
            print(f'\nåˆ†é¡å ±å‘Šï¼š')
            print(classification_report(y_test, y_pred, target_names=['ç„¡æ•ˆåå½ˆ', 'æœ‰æ•ˆåå½ˆ']))
            
            # 9. ç‰¹å¾µé‡è¦æ€§
            feature_importance = pd.DataFrame({
                'feature': feature_cols,
                'importance': model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            print(f'\nå‰ 5 é‡è¦ç‰¹å¾µï¼š')
            for idx, row in feature_importance.head(5).iterrows():
                print(f'  {row["feature"]}: {row["importance"]:.4f}')
            
            # 10. ä¿å­˜æ¨¡å‹
            symbol_dir = self.models_dir / symbol / timeframe
            symbol_dir.mkdir(parents=True, exist_ok=True)
            
            model_path = symbol_dir / 'bb_contraction_v2_model.pkl'
            scaler_path = symbol_dir / 'bb_contraction_v2_scaler.pkl'
            features_path = symbol_dir / 'bb_contraction_v2_features.json'
            
            joblib.dump(model, model_path)
            joblib.dump(scaler, scaler_path)
            
            import json
            with open(features_path, 'w') as f:
                json.dump(feature_cols, f, indent=2)
            
            print(f'\nâœ… æ¨¡å‹å·²ä¿å­˜ï¼š')
            print(f'  {model_path}')
            print(f'  {scaler_path}')
            
            return True
        
        except Exception as e:
            print(f'âœ— è¨“ç·´å¤±æ•—: {e}')
            import traceback
            traceback.print_exc()
            return False
    
    def run_full_pipeline(self):
        """
        ç‚ºæ‰€æœ‰å¹£ç¨®å’Œæ™‚é–“æ¡†æ¶è¨“ç·´
        """
        print(f'\nğŸš€ é–‹å§‹è¨“ç·´ BB æ”¶ç¸® V2 æ¨¡å‹ï¼ˆæ¸¬è©¦ç‰ˆï¼‰...')
        
        success_count = 0
        total_count = len(self.loader.symbols) * len(self.loader.timeframes)
        
        for symbol in self.loader.symbols:
            for timeframe in self.loader.timeframes:
                if self.train_single_symbol(symbol, timeframe):
                    success_count += 1
        
        separator = '=' * 70
        print(f'\n{separator}')
        print(f'âœ… è¨“ç·´å®Œæˆï¼æˆåŠŸ: {success_count}/{total_count}')
        print(f'{separator}')
        print(f'æ¨¡å‹ä¿å­˜ä½ç½®: {self.models_dir}')


if __name__ == '__main__':
    trainer = BBContractionModelTrainer()
    
    # å…ˆè¨“ç·´ä¸»è¦å¹£ç¨®æ¸¬è©¦
    symbols = ['BTCUSDT', 'ETHUSDT']
    timeframes = ['15m', '1h']
    
    print('é–‹å§‹è¨“ç·´ BB æ”¶ç¸® V2 æ¨¡å‹ï¼ˆæ¸¬è©¦ç‰ˆï¼‰...')
    print(f'å¹£ç¨®: {symbols}')
    print(f'æ™‚é–“æ¡†æ¶: {timeframes}')
    
    for symbol in symbols:
        for timeframe in timeframes:
            trainer.train_single_symbol(symbol, timeframe)
