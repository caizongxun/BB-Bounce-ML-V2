#!/usr/bin/env python3
"""
BB åå½ˆ V2 æ¨¡å‹è¨“ç·´å™¨

æ ¸å¿ƒç†è«–ï¼š
- ç„¡æ•ˆåå½ˆï¼šBB é€šé“å‘å¤–æ“´å¼µï¼ˆæ³¢å‹•ç‡ä¸Šå‡ï¼‰
- æœ‰æ•ˆåå½ˆï¼šBB é€šé“å‘å…§ç¸®å°ï¼ˆæ³¢å‹•ç‡ä¸‹é™ï¼‰

æ–°å¢ç‰¹å¾µï¼š
1. bb_width_change - BB å¯¬åº¦è®ŠåŒ–ç‡ï¼ˆæœ€é‡è¦ï¼‰
2. bb_width_percentile - BB å¯¬åº¦ç›¸å°æ­·å²ä½ç½®
3. std_change - æ¨™æº–å·®è®ŠåŒ–ç‡
4. upper_lower_distance_change - ä¸Šä¸‹è»Œé è¿‘é€Ÿåº¦
5. width_acceleration - BB å¯¬åº¦è®ŠåŒ–åŠ é€Ÿåº¦
"""

import pandas as pd
import numpy as np
from pathlib import Path
import joblib
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    classification_report, confusion_matrix, accuracy_score,
    precision_score, recall_score, f1_score, roc_auc_score
)
from xgboost import XGBClassifier
import warnings

warnings.filterwarnings('ignore')

from data_loader import CryptoDataLoader

class BBContractionFeatureExtractor:
    """æå– BB é€šé“æ”¶ç¸®ç›¸é—œç‰¹å¾µ"""
    
    @staticmethod
    def calculate_bb_bands(closes, period=20, std_dev=2):
        """è¨ˆç®—å¸ƒæ—é€šé“"""
        sma = np.mean(closes[-period:])
        std = np.std(closes[-period:])
        upper = sma + std_dev * std
        lower = sma - std_dev * std
        width = upper - lower
        return upper, sma, lower, width, std
    
    @staticmethod
    def create_features(df: pd.DataFrame, lookahead=5) -> pd.DataFrame:
        """
        å‰µå»ºç‰¹å¾µï¼Œé‡é»æ”¾åœ¨ BB é€šé“æ”¶ç¸®ç‰¹å¾µ
        """
        df = df.copy()
        close_col = 'close' if 'close' in df.columns else 'Close'
        
        # è¨ˆç®— BB å¸¶ç‹€
        bb_period = 20
        uppers = []
        middles = []
        lowers = []
        widths = []
        stds = []
        
        for i in range(len(df)):
            if i < bb_period:
                uppers.append(np.nan)
                middles.append(np.nan)
                lowers.append(np.nan)
                widths.append(np.nan)
                stds.append(np.nan)
            else:
                closes_window = df[close_col].iloc[i-bb_period:i].values
                upper, middle, lower, width, std = BBContractionFeatureExtractor.calculate_bb_bands(closes_window)
                uppers.append(upper)
                middles.append(middle)
                lowers.append(lower)
                widths.append(width)
                stds.append(std)
        
        df['bb_upper'] = uppers
        df['bb_middle'] = middles
        df['bb_lower'] = lowers
        df['bb_width'] = widths
        df['bb_std'] = stds
        
        # ========================================
        # æ–°å¢ç‰¹å¾µï¼šBB æ”¶ç¸®ç›¸é—œ
        # ========================================
        
        # 1. BB å¯¬åº¦è®ŠåŒ–ç‡ (æœ€æ ¸å¿ƒ)
        df['bb_width_change'] = df['bb_width'].pct_change()
        df['bb_width_change_3bar'] = df['bb_width'].pct_change(3)  # 3 æ ¹ K æ£’è®ŠåŒ–
        df['bb_width_change_5bar'] = df['bb_width'].pct_change(5)  # 5 æ ¹ K æ£’è®ŠåŒ–
        
        # 2. BB å¯¬åº¦åœ¨æ­·å²ä¸­çš„ä½ç½®ï¼ˆç™¾åˆ†ä½æ•¸ï¼‰
        df['bb_width_percentile'] = df['bb_width'].rolling(window=20).apply(
            lambda x: (x.iloc[-1] - x.min()) / (x.max() - x.min() + 1e-8),
            raw=False
        )
        
        # 3. æ¨™æº–å·®è®ŠåŒ–ç‡
        df['std_change'] = df['bb_std'].pct_change()
        df['std_change_3bar'] = df['bb_std'].pct_change(3)
        
        # 4. ä¸Šä¸‹è»Œé è¿‘é€Ÿåº¦ (è·é›¢è®ŠåŒ–)
        df['bb_distance'] = df['bb_upper'] - df['bb_lower']
        df['bb_distance_change'] = df['bb_distance'].pct_change()
        
        # 5. BB å¯¬åº¦è®ŠåŒ–åŠ é€Ÿåº¦ (äºŒéšå°æ•¸)
        df['bb_width_acceleration'] = df['bb_width_change'].diff()
        
        # 6. RSI å’Œå…¶ä»–å‹•é‡æŒ‡æ¨™
        delta = df[close_col].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / (loss + 1e-8)
        df['rsi_14'] = 100 - (100 / (1 + rs))
        
        # 7. åƒ¹æ ¼ç›¸å° BB ä½ç½®
        df['price_bb_position'] = (df[close_col] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'] + 1e-8)
        
        # 8. æˆäº¤é‡æ¯”
        if 'volume' in df.columns:
            df['volume_ratio'] = df['volume'] / df['volume'].rolling(window=20).mean()
        else:
            df['volume_ratio'] = 1.0
        
        # 9. æ³¢å‹•æ€§æ¯”ï¼ˆç•¶å‰æ³¢å‹•æ€§ vs æ­·å²å¹³å‡ï¼‰
        df['historical_vol'] = df[close_col].pct_change().rolling(window=20).std()
        df['vol_ratio'] = df['bb_std'] / (df['bb_std'].rolling(window=40).mean() + 1e-8)
        
        # 10. åƒ¹æ ¼å‹•é‡
        df['momentum_5'] = df[close_col].pct_change(5)
        df['momentum_10'] = df[close_col].pct_change(10)
        
        # å¡«å…… NaN
        df = df.fillna(method='bfill').fillna(method='ffill')
        
        # ========================================
        # ç”Ÿæˆæ¨™ç±¤
        # ========================================
        
        df['label_bounce_valid'] = 0  # é è¨­ç‚ºç„¡æ•ˆ
        
        for i in range(len(df) - lookahead):
            # æ¢ä»¶ 1ï¼šç•¶å‰ K æ£’è§¸åŠæˆ–æ¥è¿‘ä¸‹è»Œ
            price_to_lower = (df[close_col].iloc[i] - df['bb_lower'].iloc[i]) / (df['bb_width'].iloc[i] + 1e-8)
            is_near_lower = price_to_lower < 0.15  # åœ¨ä¸‹è»Œé™„è¿‘ 15% å…§
            
            if not is_near_lower:
                continue
            
            # æ¢ä»¶ 2ï¼šæ¥ä¸‹ä¾† lookahead æ ¹ K æ£’å…§ï¼ŒBB å¯¬åº¦å¹³å‡è®ŠåŒ–
            future_widths = df['bb_width'].iloc[i:i+lookahead].values
            future_width_change = (future_widths[-1] - future_widths[0]) / (future_widths[0] + 1e-8)
            
            # æ¢ä»¶ 3ï¼šæ¥ä¸‹ä¾† lookahead æ ¹ K æ£’å…§ï¼Œåƒ¹æ ¼è®ŠåŒ–
            future_prices = df[close_col].iloc[i:i+lookahead].values
            future_price_change = (future_prices[-1] - future_prices[0]) / (future_prices[0] + 1e-8)
            
            # æ¢ä»¶ 4ï¼šBB å¯¬åº¦æ”¶ç¸®ä¸”åƒ¹æ ¼ä¸Šå‡ = æœ‰æ•ˆåå½ˆ
            # BB å¯¬åº¦æ”¶ç¸®ï¼šfuture_width_change < -0.05 (ä¸‹é™è¶…é 5%)
            # åƒ¹æ ¼ä¸Šå‡ï¼šfuture_price_change > 0.01 (ä¸Šå‡è¶…é 1%)
            
            is_width_contracting = future_width_change < -0.05
            is_price_rising = future_price_change > 0.01
            
            if is_width_contracting and is_price_rising:
                df.loc[i, 'label_bounce_valid'] = 1  # æœ‰æ•ˆåå½ˆ
            else:
                df.loc[i, 'label_bounce_valid'] = 0  # ç„¡æ•ˆåå½ˆ
        
        return df


class BBContractionModelTrainer:
    def __init__(self, output_dir='models'):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.models_dir = self.output_dir / 'bb_contraction_v2_models'
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        self.loader = CryptoDataLoader()
    
    def train_single_symbol(self, symbol: str, timeframe: str):
        """
        ç‚ºå–®å€‹å¹£ç¨® + æ™‚é–“æ¡†æ¶è¨“ç·´ BB æ”¶ç¸®æ¨¡å‹
        """
        separator = '=' * 70
        print(f'\n{separator}')
        print(f'è¨“ç·´ {symbol} {timeframe} - BB æ”¶ç¸® V2 æ¨¡å‹')
        print(f'{separator}')
        
        try:
            # 1. ä¸‹è¼‰æ•¸æ“š
            print(f'ä¸‹è¼‰ {symbol} {timeframe} æ•¸æ“š...')
            df = self.loader.download_symbol_data(symbol, timeframe)
            if df is None or len(df) < 100:
                print(f'âŒ {symbol} {timeframe} æ•¸æ“šä¸è¶³')
                return False
            
            # 2. ç‰¹å¾µå·¥ç¨‹
            print(f'æå– BB æ”¶ç¸®ç‰¹å¾µ...')
            extractor = BBContractionFeatureExtractor()
            df = extractor.create_features(df, lookahead=5)
            
            # 3. æª¢æŸ¥æ¨™ç±¤åˆ†ä½ˆ
            label_counts = df['label_bounce_valid'].value_counts()
            print(f'\næ¨™ç±¤åˆ†ä½ˆï¼š')
            print(f'  æœ‰æ•ˆåå½ˆ (1): {label_counts.get(1, 0)} å€‹ ({label_counts.get(1, 0)/len(df)*100:.1f}%)')
            print(f'  ç„¡æ•ˆåå½ˆ (0): {label_counts.get(0, 0)} å€‹ ({label_counts.get(0, 0)/len(df)*100:.1f}%)')
            
            if label_counts.get(1, 0) < 20 or label_counts.get(0, 0) < 20:
                print(f'âš ï¸ æ¨™ç±¤æ¨£æœ¬éå°‘ï¼Œè·³éè¨“ç·´')
                return False
            
            # 4. é¸æ“‡ç‰¹å¾µ
            feature_cols = [
                # BB æ”¶ç¸®ç‰¹å¾µ (æœ€é‡è¦)
                'bb_width_change', 'bb_width_change_3bar', 'bb_width_change_5bar',
                'bb_width_percentile', 'std_change', 'std_change_3bar',
                'bb_distance_change', 'bb_width_acceleration',
                
                # å‹•é‡å’Œåƒ¹æ ¼ç‰¹å¾µ
                'rsi_14', 'price_bb_position', 'momentum_5', 'momentum_10',
                
                # æˆäº¤é‡å’Œæ³¢å‹•ç‡
                'volume_ratio', 'vol_ratio', 'historical_vol'
            ]
            
            X = df[feature_cols].fillna(method='ffill').fillna(method='bfill')
            y = df['label_bounce_valid']
            
            # ç§»é™¤ NaN è¡Œ
            mask = ~(X.isna().any(axis=1) | y.isna())
            X = X[mask]
            y = y[mask]
            
            if len(X) < 50:
                print(f'âŒ æœ‰æ•ˆæ¨£æœ¬éå°‘ï¼š{len(X)} å€‹')
                return False
            
            print(f'\nç‰¹å¾µæ•¸ï¼š{len(feature_cols)}')
            print(f'æœ‰æ•ˆæ¨£æœ¬æ•¸ï¼š{len(X)}')
            
            # 5. åˆ†å‰²è¨“ç·´/æ¸¬è©¦é›†
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )
            
            # 6. æ¨™æº–åŒ–
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # 7. è¨“ç·´æ¨¡å‹
            print(f'\nè¨“ç·´ XGBoost åˆ†é¡å™¨...')
            model = XGBClassifier(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                eval_metric='logloss',
                verbosity=0
            )
            model.fit(X_train_scaled, y_train)
            
            # 8. è©•ä¼°
            y_pred = model.predict(X_test_scaled)
            y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
            
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, zero_division=0)
            recall = recall_score(y_test, y_pred, zero_division=0)
            f1 = f1_score(y_test, y_pred, zero_division=0)
            auc = roc_auc_score(y_test, y_pred_proba) if len(set(y_test)) > 1 else 0.5
            
            print(f'\næ¸¬è©¦é›†æ€§èƒ½ï¼š')
            print(f'  æº–ç¢ºç‡: {accuracy:.4f} ({accuracy*100:.2f}%)')
            print(f'  ç²¾æº–åº¦: {precision:.4f}')
            print(f'  å¬å›ç‡: {recall:.4f}')
            print(f'  F1 åˆ†æ•¸: {f1:.4f}')
            print(f'  AUC: {auc:.4f}')
            
            print(f'\næ··æ·†çŸ©é™£ï¼š')
            print(confusion_matrix(y_test, y_pred))
            
            print(f'\nåˆ†é¡å ±å‘Šï¼š')
            print(classification_report(y_test, y_pred, target_names=['ç„¡æ•ˆåå½ˆ', 'æœ‰æ•ˆåå½ˆ']))
            
            # 9. ç‰¹å¾µé‡è¦æ€§
            feature_importance = pd.DataFrame({
                'feature': feature_cols,
                'importance': model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            print(f'\nå‰ 5 é‡è¦ç‰¹å¾µï¼š')
            for idx, row in feature_importance.head(5).iterrows():
                print(f'  {row["feature"]}: {row["importance"]:.4f}')
            
            # 10. ä¿å­˜æ¨¡å‹
            symbol_dir = self.models_dir / symbol / timeframe
            symbol_dir.mkdir(parents=True, exist_ok=True)
            
            model_path = symbol_dir / 'bb_contraction_v2_model.pkl'
            scaler_path = symbol_dir / 'bb_contraction_v2_scaler.pkl'
            features_path = symbol_dir / 'bb_contraction_v2_features.json'
            
            joblib.dump(model, model_path)
            joblib.dump(scaler, scaler_path)
            
            import json
            with open(features_path, 'w') as f:
                json.dump(feature_cols, f, indent=2)
            
            print(f'\nâœ… æ¨¡å‹å·²ä¿å­˜ï¼š')
            print(f'  {model_path}')
            print(f'  {scaler_path}')
            
            return True
        
        except Exception as e:
            print(f'âŒ è¨“ç·´å¤±æ•—: {e}')
            import traceback
            traceback.print_exc()
            return False
    
    def run_full_pipeline(self):
        """
        ç‚ºæ‰€æœ‰å¹£ç¨®å’Œæ™‚é–“æ¡†æ¶è¨“ç·´
        """
        print(f'\nğŸš€ é–‹å§‹è¨“ç·´ BB æ”¶ç¸® V2 æ¨¡å‹...')
        
        success_count = 0
        total_count = len(self.loader.symbols) * len(self.loader.timeframes)
        
        for symbol in self.loader.symbols:
            for timeframe in self.loader.timeframes:
                if self.train_single_symbol(symbol, timeframe):
                    success_count += 1
        
        separator = '=' * 70
        print(f'\n{separator}')
        print(f'âœ… è¨“ç·´å®Œæˆï¼æˆåŠŸ: {success_count}/{total_count}')
        print(f'{separator}')
        print(f'æ¨¡å‹ä¿å­˜ä½ç½®: {self.models_dir}')


if __name__ == '__main__':
    trainer = BBContractionModelTrainer()
    # å…ˆè¨“ç·´ä¸»è¦å¹£ç¨®æ¸¬è©¦
    symbols = ['BTCUSDT', 'ETHUSDT']
    timeframes = ['15m', '1h']
    
    print('é–‹å§‹è¨“ç·´ BB æ”¶ç¸® V2 æ¨¡å‹ï¼ˆæ¸¬è©¦ç‰ˆï¼‰...')
    print(f'å¹£ç¨®: {symbols}')
    print(f'æ™‚é–“æ¡†æ¶: {timeframes}')
    
    for symbol in symbols:
        for timeframe in timeframes:
            trainer.train_single_symbol(symbol, timeframe)
