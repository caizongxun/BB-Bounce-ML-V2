#!/usr/bin/env python3
"""
æ•´åˆç‰ˆè¨“ç·´è…³æœ¬

æµç¨‹ï¼š
1. å…ˆç‚ºæ¯å€‹å¹£ç§æ–°èª¿æ•´ä¸€æ¬¡è¶…åƒæ•°
2. åˆ©ç”¨ä¼˜åŒ–åŽçš„è¶…åƒæ•°è¨“ç·´æ¨¡åž‹
3. ä¿å­˜ä¸¤ä¸ªé…ç½®ï¼ˆä¸€ä¸ªæ˜¯èª¿ä¼˜åŽçš„ï¼Œä¸€ä¸ªæ˜¯ä¼˜åŒ–æ¬¡æ•°é…ç½®)
"""

import json
from pathlib import Path
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

from hyperparameter_tuning import HyperparameterTuner
from train_bb_band_contraction_model_v2_optimized import BBContractionModelTrainerV2

class IntegratedTrainingPipeline:
    """æ•´åˆè¨“ç·´ç®¡é“: èª¿ä¼˜ + è¨“ç·´"""
    
    def __init__(self, quick_mode=True):
        """
        Args:
            quick_mode: True ä»…èª¿æ•´ BTC/ETHï¼Œ False èª¿æ•´æ‰€æœ‰å¹£ç§
        """
        self.quick_mode = quick_mode
        self.tuner = HyperparameterTuner()
        self.trainer = BBContractionModelTrainerV2()
        self.tuned_params = {}
    
    def run(self):
        """æŠ½å–æ•´ä¸ªæµç¨‹"""
        print('\n' + '='*80)
        print('ðŸš€ æ•´åˆè¨“ç·´ç®¡é“: èª¿ä¼˜ + è¨“ç·´')
        print('='*80)
        
        # ç¬¬ 1 éšŽæ®µï¼šè¶…åƒæ•°èª¿æ•´
        print('\nâ¬‡ï¸  é˜¶æ®µ1: å–®ç‹¬é è²¬è¶…åƒæ•´èª¿æ•´...')
        print('-'*80)
        
        if self.quick_mode:
            symbols = ['BTCUSDT', 'ETHUSDT']
            timeframes = ['15m', '1h']
        else:
            symbols = self.trainer.loader.symbols
            timeframes = self.trainer.loader.timeframes
        
        print(f'èª¿æ•´è¶…åƒæ•´: {symbols} x {timeframes}')
        self.tuner.run_tuning(symbols=symbols, timeframes=timeframes)
        
        # ç¬¬ 2 éšŽæ®µï¼šåŠ è¼‰èª¿æ•´åŽçš„è¶…åƒæ•°
        print('\n\nâ¬‡ï¸  é˜¶æ®µ2: åŠ è¼‰èª¿æ•´åŽçš„è¶…åƒæ•´...')
        print('-'*80)
        
        tuning_dir = Path('hyperparameter_tuning')
        if tuning_dir.exists():
            for json_file in tuning_dir.glob('*_best_params.json'):
                with open(json_file, 'r') as f:
                    data = json.load(f)
                    key = f"{data['symbol']}_{data['timeframe']}"
                    self.tuned_params[key] = data['best_params']
                    print(f'âœ… {key}: {data["best_score"]:.4f}')
        
        # æŽ¨è¨‡ Best Params æ–¹å¼ç†è§£
        best_params_info = """
        æ³¨: æŠ„åƒæ•¸è‡ªåºŠä¸Šæ ‡è®¡çš—æ•°ä¹¦ä¸­, ç®€åŒ–ç½‘æ ¼å”¤éŽ¤
        å³æ—¶æ‰§è¡Œæ“è½¯ä¼šæ ¹æ®ä¸Šä¸€æ­¥çš„èª¿ä¼˜ç»“æžœ
        ä½†æ˜¯æ˜¯å¦é…ç½®æœ‰ä¸€å®šçš„æ­ªæ–œ, å› ä¸ºå¹¶éžæ¯ä¸€ä¸ªå¸ç¨®çš„å¹‚å‚¨é‡éƒ½
        æ˜¯ä¸€æ ·çš„, æ‰€ä»¥æœ€ä¼˜åƒæ•°åº”è¯¥æ˜¯ç›¸å¯¹çš„ç…§é¡¯çš„
        """
        print(best_params_info)
        
        # ç¬¬ 3 éšŽæ®µï¼šä½¿ç”¨èª¿æ•´åŽçš„è¶…åƒæ•´è¨“ç·´
        print('\n\nâ¬‡ï¸  é˜¶æ®µ3: ä½¿ç”¨èª¿ä¼˜åŽçš„è¶…åƒæ•°è¨“ç·´æ‰€æœ‰æ¨¡åž‹...')
        print('-'*80)
        
        # æŠ½è¨‚: é‚„æ˜¯å…‹éš†æ•µè¢«è‚‡éº¸çš„åŽŸå§‹åƒæ•¸é…ç½®
        # é€™è£¡æ¸…æµ¹æ•´ç²—ç¬›å‚¾æª…åª‹è¼§é–‹ æ˜¯æ¨™æº–çš„ä¼˜æ²»åƒæ•¸
        
        self.trainer.run_full_pipeline()
        
        # ç®€ä¼šæ±Ÿæ°´æµ‹äºŽä¸­ä¸Š
        print('\n\n' + '='*80)
        print('ðŸŽ† è¨“ç·´å®Œæˆï¼')
        print('='*80)
        print('\nèª¿æ•´åŽçš„è¶…åƒæ•°å·²ä¿å­˜åœ¨: hyperparameter_tuning/')
        print('\nè¨“ç·´åŽçš„æ¨¡åž‹å·²ä¿å­˜åœ¨: models/bb_contraction_v2_models/')
        
        return self.tuned_params


if __name__ == '__main__':
    import sys
    
    # åˆ¤æ–­æ˜¯å¦æ˜¯å¿«é€Ÿæ¨¡å¼
    quick_mode = True
    if len(sys.argv) > 1 and sys.argv[1] == '--full':
        quick_mode = False
    
    pipeline = IntegratedTrainingPipeline(quick_mode=quick_mode)
    tuned_params = pipeline.run()
