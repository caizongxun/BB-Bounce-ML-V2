#!/usr/bin/env python3
"""
BB åå½ˆ V2 æ¨¡å‹è¨“ç·´å™¨ - å„ªåŒ–ç‰ˆ

æ”¹é€²é»ï¼š
1. æ¨™ç±¤é‚è¼¯å„ªåŒ–ï¼šæ›´åš´æ ¼çš„åå½ˆæ¢ä»¶ + å›æ’¤é™åˆ¶
2. æ–°å¢ç‰¹å¾µï¼šBB å¯¬åº¦è¶¨å‹¢ + æˆäº¤é‡å¼·åº¦ + å‹•é‡èåˆ + æ“ å£“è©•åˆ†
3. è¶…åƒèª¿æ•´ï¼šæ›´æ·±çš„æ¨¹ + æ›´ä½çš„å­¸ç¿’ç‡ + æ­£å‰‡åŒ–
4. å…¨å¹£ç¨®è¨“ç·´ï¼š22 å€‹å¹£ç¨® Ã— 2 å€‹æ™‚æ¡† = 44 å€‹æ¨¡å‹
"""

import pandas as pd
import numpy as np
from pathlib import Path
import joblib
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    classification_report, confusion_matrix, accuracy_score,
    precision_score, recall_score, f1_score, roc_auc_score
)
from xgboost import XGBClassifier
import warnings
import logging
from datetime import datetime

warnings.filterwarnings('ignore')

# æ—¥èªŒè¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

try:
    from data_loader import CryptoDataLoader
except ImportError:
    logger.error('æ‰¾ä¸åˆ° data_loaderï¼Œè«‹ç¢ºä¿åœ¨æ­£ç¢ºçš„ç›®éŒ„')
    exit(1)

# ============================================================
# å„ªåŒ–çš„ç‰¹å¾µæå–å™¨
# ============================================================

class BBContractionFeatureExtractorV3:
    """æ”¹é€²ç‰ˆç‰¹å¾µæå– - åŠ å…¥æ–°çš„ BB æ”¶ç¸®æŒ‡æ¨™"""
    
    @staticmethod
    def calculate_bb_bands(closes, period=20, std_dev=2):
        """è¨ˆç®— BB å¸¶"""
        if len(closes) < period:
            return None, None, None, None, None
        
        sma = np.mean(closes[-period:])
        std = np.std(closes[-period:])
        upper = sma + std_dev * std
        lower = sma - std_dev * std
        width = upper - lower
        return upper, sma, lower, width, std
    
    @staticmethod
    def create_features(df: pd.DataFrame, timeframe: str, lookahead=5) -> pd.DataFrame:
        """
        å»ºç«‹ç‰¹å¾µä¸¦ç”Ÿæˆæ¨™ç±¤
        
        Args:
            df: åŸå§‹ OHLCV æ•¸æ“š
            timeframe: '15m' æˆ– '1h'
            lookahead: å‘å‰çœ‹çš„ K æ£’æ•¸
        """
        df = df.copy()
        close_col = 'close' if 'close' in df.columns else 'Close'
        
        # ========================================
        # ç¬¬ 1 æ­¥ï¼šè¨ˆç®— Bollinger Bands
        # ========================================
        
        bb_period = 20
        uppers = []
        middles = []
        lowers = []
        widths = []
        stds = []
        
        for i in range(len(df)):
            if i < bb_period:
                uppers.append(np.nan)
                middles.append(np.nan)
                lowers.append(np.nan)
                widths.append(np.nan)
                stds.append(np.nan)
            else:
                closes_window = df[close_col].iloc[i-bb_period:i].values
                result = BBContractionFeatureExtractorV3.calculate_bb_bands(closes_window)
                if result[0] is not None:
                    upper, middle, lower, width, std = result
                    uppers.append(upper)
                    middles.append(middle)
                    lowers.append(lower)
                    widths.append(width)
                    stds.append(std)
                else:
                    uppers.append(np.nan)
                    middles.append(np.nan)
                    lowers.append(np.nan)
                    widths.append(np.nan)
                    stds.append(np.nan)
        
        df['bb_upper'] = uppers
        df['bb_middle'] = middles
        df['bb_lower'] = lowers
        df['bb_width'] = widths
        df['bb_std'] = stds
        
        # ========================================
        # ç¬¬ 2 æ­¥ï¼šè¨ˆç®— BB å¯¬åº¦è®ŠåŒ–ç‰¹å¾µ
        # ========================================
        
        df['bb_width_change_1bar'] = df['bb_width'].pct_change(1)
        df['bb_width_change_2bar'] = df['bb_width'].pct_change(2)
        df['bb_width_change_3bar'] = df['bb_width'].pct_change(3)
        df['bb_width_change_5bar'] = df['bb_width'].pct_change(5)
        
        # BB å¯¬åº¦åœ¨æ­·å²ä¸­çš„ç›¸å°ä½ç½®
        df['bb_width_percentile'] = df['bb_width'].rolling(window=20).apply(
            lambda x: (x.iloc[-1] - x.min()) / (x.max() - x.min() + 1e-8),
            raw=False
        )
        
        # æ¨™æº–å·®è®ŠåŒ–
        df['std_change'] = df['bb_std'].pct_change()
        df['std_change_3bar'] = df['bb_std'].pct_change(3)
        
        # ä¸Šä¸‹è»Œè·é›¢è®ŠåŒ–
        df['bb_distance'] = df['bb_upper'] - df['bb_lower']
        df['bb_distance_change'] = df['bb_distance'].pct_change()
        
        # BB å¯¬åº¦åŠ é€Ÿåº¦
        df['bb_width_acceleration'] = df['bb_width_change_1bar'].diff()
        
        # ========================================
        # ç¬¬ 3 æ­¥ï¼šæ–°å¢ç‰¹å¾µ - BB æ”¶ç¸®æŒ‡æ¨™
        # ========================================
        
        # 1. BB å¯¬åº¦è¶¨å‹¢ (10 æ ¹ K æ£’ç·šæ€§å›æ­¸æ–œç‡)
        df['bb_width_trend'] = df['bb_width'].rolling(window=10).apply(
            lambda x: np.polyfit(np.arange(len(x)), x, 1)[0] if len(x) > 1 else 0,
            raw=False
        )
        
        # 2. BB æ“ å£“åˆ†æ•¸ (å¯¬åº¦ç™¾åˆ†ä½ - å¯¬åº¦è®ŠåŒ–å¹…åº¦)
        df['bb_squeeze_score'] = df['bb_width_percentile'] - df['bb_width_change_2bar'].abs()
        
        # 3. æˆäº¤é‡å¼·åº¦
        if 'volume' in df.columns:
            df['volume_strength'] = df['volume'] / df['volume'].rolling(window=30).mean()
        else:
            df['volume_strength'] = 1.0
        
        # 4. å‹•é‡èåˆ (RSI æ­£è¦åŒ– + åƒ¹æ ¼å‹•é‡)
        delta = df[close_col].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / (loss + 1e-8)
        df['rsi_14'] = 100 - (100 / (1 + rs))
        
        rsi_normalized = (df['rsi_14'] - 50) / 50
        df['momentum_5'] = df[close_col].pct_change(5)
        df['momentum_10'] = df[close_col].pct_change(10)
        df['momentum_confluence'] = (rsi_normalized + df['momentum_5'] * 100) / 2
        
        # ========================================
        # ç¬¬ 4 æ­¥ï¼šå…¶ä»–ç‰¹å¾µ
        # ========================================
        
        # åƒ¹æ ¼ç›¸å° BB ä½ç½®
        df['price_bb_position'] = (df[close_col] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'] + 1e-8)
        
        # æ³¢å‹•ç‡æ¯”
        df['historical_vol'] = df[close_col].pct_change().rolling(window=20).std()
        df['vol_ratio'] = df['bb_std'] / (df['bb_std'].rolling(window=40).mean() + 1e-8)
        
        if 'volume' in df.columns:
            df['volume_ratio'] = df['volume'] / df['volume'].rolling(window=20).mean()
        else:
            df['volume_ratio'] = 1.0
        
        # å¡«å…… NaN
        df = df.fillna(method='bfill').fillna(method='ffill')
        
        # ========================================
        # ç¬¬ 5 æ­¥ï¼šç”Ÿæˆå„ªåŒ–çš„æ¨™ç±¤
        # ========================================
        
        df['label_bounce_valid'] = -1  # é è¨­ç‚ºå¿½ç•¥
        
        # æ ¹æ“šæ™‚æ¡†è¨­å®šä¸åŒçš„åå½ˆé–¾å€¼
        if timeframe == '15m':
            min_rebound = 0.008  # 0.8%
            max_drawdown = -0.005  # -0.5%
        else:  # 1h
            min_rebound = 0.015  # 1.5%
            max_drawdown = -0.010  # -1%
        
        for i in range(len(df) - lookahead):
            # æ¢ä»¶ 1ï¼šåƒ¹æ ¼æ¥è¿‘ä¸‹è»Œ
            if pd.isna(df['bb_lower'].iloc[i]) or pd.isna(df['bb_upper'].iloc[i]):
                continue
            
            price_to_lower = (df[close_col].iloc[i] - df['bb_lower'].iloc[i]) / (df['bb_width'].iloc[i] + 1e-8)
            is_near_lower = price_to_lower < 0.20
            
            if not is_near_lower:
                continue
            
            # è¨ˆç®—æœªä¾† lookahead æ ¹ K æ£’çš„çµ±è¨ˆ
            future_closes = df[close_col].iloc[i:i+lookahead].values
            future_widths = df['bb_width'].iloc[i:i+lookahead].values
            
            if len(future_closes) < lookahead or len(future_widths) < lookahead:
                continue
            
            # éå» 3 æ ¹ K æ£’çš„å¹³å‡å¯¬åº¦
            past_widths = df['bb_width'].iloc[max(0, i-3):i].values
            if len(past_widths) == 0:
                continue
            
            past_avg_width = np.mean(past_widths)
            future_avg_width = np.mean(future_widths)
            
            if past_avg_width <= 0:
                continue
            
            # æ¢ä»¶ 2ï¼šè¨ˆç®— BB å¯¬åº¦è®ŠåŒ–
            width_change_ratio = (future_avg_width - past_avg_width) / past_avg_width
            
            # æ¢ä»¶ 3ï¼šè¨ˆç®—åƒ¹æ ¼è®ŠåŒ–å’Œæœ€å¤§å›æ’¤
            future_price_change = (future_closes[-1] - future_closes[0]) / (future_closes[0] + 1e-8)
            max_dd = (np.min(future_closes) / future_closes[0] - 1) if future_closes[0] > 0 else 0
            
            # æ¢ä»¶ 4ï¼šè¨ˆç®—æ¨™æº–å·®è®ŠåŒ–
            past_std = df['bb_std'].iloc[max(0, i-3):i].mean() if i >= 3 else df['bb_std'].iloc[i]
            future_std = df['bb_std'].iloc[i:i+lookahead].mean()
            std_change = (future_std - past_std) / (past_std + 1e-8)
            
            # æ¢ä»¶ 5ï¼šæˆäº¤é‡ç¢ºèª
            current_volume = df['volume'].iloc[i] if 'volume' in df.columns else 1
            avg_volume = df['volume'].iloc[max(0, i-20):i].mean() if i >= 20 and 'volume' in df.columns else 1
            volume_ratio = current_volume / (avg_volume + 1e-8)
            
            # ========================================
            # æ¨™ç±¤æ±ºç­–é‚è¼¯ï¼ˆå„ªåŒ–ç‰ˆï¼‰
            # ========================================
            
            # ã€æ¨™ç±¤ 1ã€‘å¼·æœ‰æ•ˆåå½ˆ
            if (width_change_ratio < -0.10 and  # BB æ˜é¡¯æ”¶ç¸® >= 10%
                future_price_change > min_rebound and  # åå½ˆé”åˆ°æœ€ä½è¦æ±‚
                max_dd > max_drawdown and  # æ²’æœ‰å¤§å¹…å›æ’¤
                std_change < 0 and  # æ³¢å‹•ç‡ä¸‹é™
                volume_ratio > 0.8):  # å¯èƒ½æœ‰æˆäº¤é‡é€²å ´
                df.loc[i, 'label_bounce_valid'] = 1
            
            # ã€æ¨™ç±¤ 1ã€‘ä¸­ç­‰æœ‰æ•ˆåå½ˆ
            elif (width_change_ratio < -0.05 and  # BB æ”¶ç¸® >= 5%
                  future_price_change > min_rebound * 0.7 and  # åå½ˆé”åˆ° 70% çš„æœ€ä½è¦æ±‚
                  max_dd > max_drawdown * 0.5 and  # å›æ’¤æ§åˆ¶åœ¨ 50% ä»¥å…§
                  std_change < 0.05):  # æ³¢å‹•ç‡ç©©å®š
                df.loc[i, 'label_bounce_valid'] = 1
            
            # ã€æ¨™ç±¤ 1ã€‘BB å¯¬åº¦åœ¨æ­·å²ä½ä½
            elif (df['bb_width_percentile'].iloc[i] < 0.25 and  # å¯¬åº¦åœ¨æœ€ä½ 25%
                  is_near_lower and
                  future_price_change > min_rebound * 0.5):  # åªè¦æœ‰åå½ˆè·¡è±¡
                df.loc[i, 'label_bounce_valid'] = 1
            
            # ã€æ¨™ç±¤ 0ã€‘æ˜é¡¯ç„¡æ•ˆåå½ˆ
            elif (width_change_ratio > 0.15 and  # BB æ˜é¡¯æ“´å¼µ >= 15%
                  future_price_change < -0.002 and  # æ²’åå½ˆåè€Œä¸‹è·Œ
                  std_change > 0.1):  # æ³¢å‹•ç‡ä¸Šå‡
                df.loc[i, 'label_bounce_valid'] = 0
            
            # ã€æ¨™ç±¤ 0ã€‘æ¬¡ç­‰ç„¡æ•ˆåå½ˆ
            elif (width_change_ratio > 0.05 and  # BB æŒçºŒæ“´å¼µ >= 5%
                  future_price_change < 0.001):  # å¹¾ä¹æ²’åå½ˆ
                df.loc[i, 'label_bounce_valid'] = 0
            
            # å…¶ä»–æƒ…æ³ï¼šä¿æŒ -1ï¼ˆå¿½ç•¥ï¼‰
        
        return df


class BBContractionModelTrainerV2:
    """å„ªåŒ–ç‰ˆè¨“ç·´å™¨"""
    
    def __init__(self, output_dir='models'):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.models_dir = self.output_dir / 'bb_contraction_v2_models'
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        self.loader = CryptoDataLoader()
        
        # çµ±è¨ˆæ•¸æ“š
        self.stats = {
            'total': 0,
            'success': 0,
            'failed': 0,
            'total_models': 0
        }
    
    def train_single_symbol(self, symbol: str, timeframe: str):
        """
        è¨“ç·´å–®ä¸€å¹£ç¨® + æ™‚æ¡†çš„æ¨¡å‹
        """
        separator = '=' * 80
        print(f'\n{separator}')
        print(f'è¨“ç·´ {symbol} {timeframe} - BB æ”¶ç¸® V2 å„ªåŒ–æ¨¡å‹')
        print(f'{separator}')
        
        try:
            self.stats['total_models'] += 1
            
            # 1. ä¸‹è¼‰æ•¸æ“š
            print(f'â¬‡ï¸  ä¸‹è¼‰ {symbol} {timeframe} æ•¸æ“š...')
            df = self.loader.download_symbol_data(symbol, timeframe)
            if df is None or len(df) < 100:
                print(f'âœ— {symbol} {timeframe} æ•¸æ“šä¸è¶³')
                self.stats['failed'] += 1
                return False
            
            print(f'âœ… {symbol} {timeframe}: {len(df)} æ ¹ K æ£’')
            
            # 2. æå–ç‰¹å¾µ
            print(f'ğŸ”§ æå–ç‰¹å¾µ...')
            extractor = BBContractionFeatureExtractorV3()
            df = extractor.create_features(df, timeframe=timeframe, lookahead=5)
            
            # 3. ç¯©é¸æœ‰æ•ˆæ¨™ç±¤
            df_labeled = df[df['label_bounce_valid'] != -1].copy()
            
            label_counts = df_labeled['label_bounce_valid'].value_counts()
            print(f'\nğŸ“Š æ¨™ç±¤åˆ†å¸ƒï¼š')
            print(f'  æœ‰æ•ˆåå½ˆ (1): {label_counts.get(1, 0):,} å€‹ ({label_counts.get(1, 0)/len(df_labeled)*100:.1f}%)')
            print(f'  ç„¡æ•ˆåå½ˆ (0): {label_counts.get(0, 0):,} å€‹ ({label_counts.get(0, 0)/len(df_labeled)*100:.1f}%)')
            
            if len(df_labeled) < 50:
                print(f'âœ— æœ‰æ•ˆæ¨£æœ¬éå°‘ï¼š{len(df_labeled)} å€‹')
                self.stats['failed'] += 1
                return False
            
            if label_counts.get(1, 0) < 5 or label_counts.get(0, 0) < 5:
                print(f'âœ— æŸé¡åˆ¥æ¨£æœ¬éå°‘')
                self.stats['failed'] += 1
                return False
            
            # 4. é¸æ“‡ç‰¹å¾µ
            feature_cols = [
                'bb_width_change_1bar', 'bb_width_change_2bar', 'bb_width_change_3bar', 'bb_width_change_5bar',
                'bb_width_percentile', 'std_change', 'std_change_3bar',
                'bb_distance_change', 'bb_width_acceleration',
                'bb_width_trend', 'bb_squeeze_score',  # æ–°ç‰¹å¾µ
                'rsi_14', 'price_bb_position', 'momentum_5', 'momentum_10', 'momentum_confluence',  # æ–°ç‰¹å¾µ
                'volume_ratio', 'volume_strength', 'vol_ratio', 'historical_vol'  # æ–°ç‰¹å¾µ
            ]
            
            X = df_labeled[feature_cols]
            y = df_labeled['label_bounce_valid']
            
            # ç§»é™¤ NaN
            mask = ~X.isna().any(axis=1)
            X = X[mask]
            y = y[mask]
            
            if len(X) < 30:
                print(f'âœ— æœ‰æ•ˆæ¨£æœ¬å¤ªå°‘ï¼š{len(X)} å€‹')
                self.stats['failed'] += 1
                return False
            
            print(f'\nğŸ“ˆ ç‰¹å¾µæ•¸ï¼š{len(feature_cols)}')
            print(f'ğŸ“ˆ æœ‰æ•ˆæ¨£æœ¬ï¼š{len(X)}')
            
            # 5. åˆ†å‰²è¨“ç·´/æ¸¬è©¦é›†
            try:
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42, stratify=y
                )
            except:
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42
                )
            
            # 6. æ¨™æº–åŒ–
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # 7. è¨“ç·´æ¨¡å‹ï¼ˆå„ªåŒ–è¶…åƒï¼‰
            print(f'\nğŸ¤– è¨“ç·´ XGBoost åˆ†é¡å™¨ (å„ªåŒ–è¶…åƒ)...')
            model = XGBClassifier(
                n_estimators=250,
                max_depth=7,
                learning_rate=0.05,
                subsample=0.8,
                colsample_bytree=0.7,
                random_state=42,
                eval_metric='logloss',
                verbosity=0,
                reg_alpha=1.0,
                reg_lambda=2.0,
                scale_pos_weight=len(y[y==0]) / (len(y[y==1]) + 1e-8) if len(y[y==1]) > 0 else 1
            )
            model.fit(X_train_scaled, y_train)
            
            # 8. è©•ä¼°
            y_pred = model.predict(X_test_scaled)
            y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
            
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, zero_division=0)
            recall = recall_score(y_test, y_pred, zero_division=0)
            f1 = f1_score(y_test, y_pred, zero_division=0)
            auc = roc_auc_score(y_test, y_pred_proba) if len(set(y_test)) > 1 else 0.5
            
            print(f'\nğŸ“Š æ¸¬è©¦é›†æ€§èƒ½ï¼š')
            print(f'  æº–ç¢ºç‡: {accuracy:.4f} ({accuracy*100:.2f}%)')
            print(f'  ç²¾æº–åº¦: {precision:.4f}')
            print(f'  å¬å›ç‡: {recall:.4f}')
            print(f'  F1 åˆ†æ•¸: {f1:.4f}')
            print(f'  AUC: {auc:.4f}')
            
            print(f'\nğŸ¯ æ··æ·†çŸ©é™£ï¼š')
            cm = confusion_matrix(y_test, y_pred)
            print(f'  {cm}')
            
            # ç‰¹å¾µé‡è¦æ€§
            feature_importance = pd.DataFrame({
                'feature': feature_cols,
                'importance': model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            print(f'\nâ­ å‰ 8 é‡è¦ç‰¹å¾µï¼š')
            for idx, row in feature_importance.head(8).iterrows():
                print(f'  {row["feature"]}: {row["importance"]:.4f}')
            
            # 9. ä¿å­˜æ¨¡å‹
            symbol_dir = self.models_dir / symbol / timeframe
            symbol_dir.mkdir(parents=True, exist_ok=True)
            
            model_path = symbol_dir / 'bb_contraction_v2_model.pkl'
            scaler_path = symbol_dir / 'bb_contraction_v2_scaler.pkl'
            features_path = symbol_dir / 'bb_contraction_v2_features.json'
            
            joblib.dump(model, model_path)
            joblib.dump(scaler, scaler_path)
            
            import json
            with open(features_path, 'w') as f:
                json.dump(feature_cols, f, indent=2)
            
            print(f'\nâœ… æ¨¡å‹å·²ä¿å­˜ï¼š')
            print(f'  {model_path}')
            print(f'  {scaler_path}')
            
            self.stats['success'] += 1
            return True
        
        except Exception as e:
            print(f'âœ— è¨“ç·´å¤±æ•—: {e}')
            import traceback
            traceback.print_exc()
            self.stats['failed'] += 1
            return False
    
    def run_full_pipeline(self):
        """
        è¨“ç·´æ‰€æœ‰å¹£ç¨® Ã— æ™‚æ¡†
        """
        print(f'\nğŸš€ é–‹å§‹è¨“ç·´æ‰€æœ‰å¹£ç¨®çš„ BB æ”¶ç¸® V2 å„ªåŒ–æ¨¡å‹...')
        print(f'ğŸ¯ ç›®æ¨™ï¼š{len(self.loader.symbols)} å€‹å¹£ç¨® Ã— {len(self.loader.timeframes)} å€‹æ™‚æ¡† = {len(self.loader.symbols) * len(self.loader.timeframes)} å€‹æ¨¡å‹')
        print(f'\nå¹£ç¨®: {self.loader.symbols}')
        print(f'æ™‚æ¡†: {self.loader.timeframes}')
        
        start_time = datetime.now()
        
        for idx, symbol in enumerate(self.loader.symbols, 1):
            print(f'\n\n[é€²åº¦] {idx}/{len(self.loader.symbols)} - {symbol}')
            
            for timeframe in self.loader.timeframes:
                self.train_single_symbol(symbol, timeframe)
        
        end_time = datetime.now()
        duration = end_time - start_time
        
        # æœ€çµ‚çµ±è¨ˆ
        separator = '=' * 80
        print(f'\n{separator}')
        print(f'ğŸ‰ è¨“ç·´å®Œæˆï¼')
        print(f'{separator}')
        print(f'æˆåŠŸ: {self.stats["success"]}/{self.stats["total_models"]}')
        print(f'å¤±æ•—: {self.stats["failed"]}/{self.stats["total_models"]}')
        print(f'è€—æ™‚: {duration}')
        print(f'æ¨¡å‹ä¿å­˜ä½ç½®: {self.models_dir}')
        print(f'{separator}')


if __name__ == '__main__':
    trainer = BBContractionModelTrainerV2()
    trainer.run_full_pipeline()
