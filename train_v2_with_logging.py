#!/usr/bin/env python3
"""
å®Œæ•´ç‰ˆè¨“ç·´è…³æœ¬â€”æ•´åˆè¨“ç·´ + è©³æ ‡è¨ˆéŒ„

ç‰¹è¨˜ï¼š
1. è‡ªå‹•è²¬è¨˜æ•´å€‹è¨“ç·´éŽç¨‹åˆ° JSON
2. ç´°æ¶‰è¨±å¯ç¾¤ç¶„å‰ä¼˜è§£æ¨™æº–åŒ–åˆ°æ—¥èªŒæª”
3. æ¯ä¸€å€‹å¹£ç¨®ã€æ™‚æ¡†çš„æ€§èƒ½æœƒåˆ¥å„²çµ…
4. ç´•å¯¶ç‰¹å®˜å¸«è©³è¨ŠAPIæ”¯æŒ
"""

import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any
import sys

from hyperparameter_tuning import HyperparameterTuner
from train_bb_band_contraction_model_v2_optimized import BBContractionModelTrainerV2

# ============================================================
# æ—¥èªŒéšŽè¨­å®š
# ============================================================

class TrainingLogger:
    """è©³æ ‡è¨˜éŒ„ - JSON + LOG ä¸¦å¸³æ‰“å°"""
    
    def __init__(self, log_dir='training_logs'):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # æ™‚é–“æˆ·è¨˜
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.session_id = timestamp
        
        # æ¨™æº– LOG æª”
        self.log_file = self.log_dir / f'training_{timestamp}.log'
        
        # JSON çµ±è¨ˆæª”
        self.json_file = self.log_dir / f'training_results_{timestamp}.json'
        
        # è©•åˆ†äº’å‹•æ–¹æˆ´
        self.console_handler = logging.StreamHandler()
        self.file_handler = logging.FileHandler(self.log_file, encoding='utf-8')
        
        # è¨­ç½® logger
        self.logger = logging.getLogger('TrainingLogger')
        self.logger.setLevel(logging.DEBUG)
        
        formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        
        self.console_handler.setFormatter(formatter)
        self.file_handler.setFormatter(formatter)
        
        self.logger.addHandler(self.console_handler)
        self.logger.addHandler(self.file_handler)
        
        # çµ±è¨ˆæ•¸æ“š
        self.results = {
            'session_id': self.session_id,
            'start_time': datetime.now().isoformat(),
            'end_time': None,
            'duration_seconds': 0,
            'tuning_results': [],
            'training_results': [],
            'summary': {
                'total_tuning_tasks': 0,
                'successful_tuning': 0,
                'failed_tuning': 0,
                'total_training_tasks': 0,
                'successful_training': 0,
                'failed_training': 0,
                'average_accuracy_1h': 0,
                'average_accuracy_15m': 0,
                'average_precision_1h': 0,
                'average_precision_15m': 0,
            }
        }
    
    def log_tuning_start(self, symbol: str, timeframe: str):
        """è¨˜éŒ„èª¿æ•´é–‹å§‹"""
        msg = f'\n[TUNING START] {symbol} {timeframe}'
        self.logger.info(msg)
    
    def log_tuning_result(self, symbol: str, timeframe: str, params: Dict[str, Any], score: float):
        """è¨˜éŒ„èª¿æ•´çµæžœ"""
        result = {
            'symbol': symbol,
            'timeframe': timeframe,
            'params': params,
            'score': float(score),
            'timestamp': datetime.now().isoformat()
        }
        
        self.results['tuning_results'].append(result)
        self.results['summary']['total_tuning_tasks'] += 1
        self.results['summary']['successful_tuning'] += 1
        
        msg = f'[TUNING SUCCESS] {symbol} {timeframe} - Score: {score:.4f}'
        self.logger.info(msg)
        self.logger.debug(f'  Params: {params}')
    
    def log_tuning_error(self, symbol: str, timeframe: str, error: str):
        """è¨˜éŒ„èª¿æ•´éŒ¯èª¤"""
        self.results['summary']['total_tuning_tasks'] += 1
        self.results['summary']['failed_tuning'] += 1
        
        msg = f'[TUNING FAILED] {symbol} {timeframe} - Error: {error}'
        self.logger.error(msg)
    
    def log_training_start(self, symbol: str, timeframe: str):
        """è¨˜éŒ„è¨“ç·´é–‹å§‹"""
        msg = f'\n[TRAINING START] {symbol} {timeframe}'
        self.logger.info(msg)
    
    def log_training_result(self, symbol: str, timeframe: str, metrics: Dict[str, Any]):
        """è¨˜éŒ„è¨“ç·´çµæžœ"""
        result = {
            'symbol': symbol,
            'timeframe': timeframe,
            'metrics': metrics,
            'timestamp': datetime.now().isoformat()
        }
        
        self.results['training_results'].append(result)
        self.results['summary']['total_training_tasks'] += 1
        self.results['summary']['successful_training'] += 1
        
        # æ›´æ–°æ™‚æ¡†å¹³å‡å‡†ç¢ºçŽ‡å’Œç²¾æº–åº¦
        if timeframe == '1h':
            accuracies = [r['metrics']['accuracy'] for r in self.results['training_results'] if r['timeframe'] == '1h']
            precisions = [r['metrics']['precision'] for r in self.results['training_results'] if r['timeframe'] == '1h']
            self.results['summary']['average_accuracy_1h'] = sum(accuracies) / len(accuracies) if accuracies else 0
            self.results['summary']['average_precision_1h'] = sum(precisions) / len(precisions) if precisions else 0
        else:
            accuracies = [r['metrics']['accuracy'] for r in self.results['training_results'] if r['timeframe'] == '15m']
            precisions = [r['metrics']['precision'] for r in self.results['training_results'] if r['timeframe'] == '15m']
            self.results['summary']['average_accuracy_15m'] = sum(accuracies) / len(accuracies) if accuracies else 0
            self.results['summary']['average_precision_15m'] = sum(precisions) / len(precisions) if precisions else 0
        
        msg = f'[TRAINING SUCCESS] {symbol} {timeframe} - Accuracy: {metrics["accuracy"]:.4f}, Precision: {metrics["precision"]:.4f}'
        self.logger.info(msg)
    
    def log_training_error(self, symbol: str, timeframe: str, error: str):
        """è¨˜éŒ„è¨“ç·´éŒ¯èª¤"""
        self.results['summary']['total_training_tasks'] += 1
        self.results['summary']['failed_training'] += 1
        
        msg = f'[TRAINING FAILED] {symbol} {timeframe} - Error: {error}'
        self.logger.error(msg)
    
    def save_results(self):
        """ä¿å­˜ JSON çµ±è¨ˆè©§å¬"""
        self.results['end_time'] = datetime.now().isoformat()
        
        start = datetime.fromisoformat(self.results['start_time'])
        end = datetime.fromisoformat(self.results['end_time'])
        self.results['duration_seconds'] = (end - start).total_seconds()
        
        with open(self.json_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f'\nâœ… è©³æ ‡è¨˜éŒ„å·²ä¿å­˜ï¼š{self.json_file}')
    
    def print_summary(self):
        """åˆ—å°æ±è¨ˆè¨˜éŒ„"""
        separator = '='*80
        print(f'\n{separator}')
        print(f'ðŸŽ† è¨“ç·´çµ±è¨ˆç´¡æ¬¡é©™')
        print(f'{separator}')
        
        summary = self.results['summary']
        
        print(f'\nðŸŽ¯ èª¿æ•´çµæžœï¼š')
        print(f'  æˆåŠŸ: {summary["successful_tuning"]}/{summary["total_tuning_tasks"]}')
        print(f'  å¤±æ•—: {summary["failed_tuning"]}/{summary["total_tuning_tasks"]}')
        
        print(f'\nðŸ“ˆ è¨“ç·´çµæžœï¼š')
        print(f'  æˆåŠŸ: {summary["successful_training"]}/{summary["total_training_tasks"]}')
        print(f'  å¤±æ•—: {summary["failed_training"]}/{summary["total_training_tasks"]}')
        
        print(f'\nðŸƒ 1h æ™‚æ¡†æ€§èƒ½ï¼š')
        print(f'  å¹³å‡æº–ç¢ºçŽ‡: {summary["average_accuracy_1h"]:.4f} ({summary["average_accuracy_1h"]*100:.2f}%)')
        print(f'  å¹³å‡ç²¾æº–åº¦: {summary["average_precision_1h"]:.4f}')
        
        print(f'\nðŸƒ 15m æ™‚æ™‚æ¡†æ€§èƒ½ï¼š')
        print(f'  å¹³å‡æº–ç¢ºçŽ‡: {summary["average_accuracy_15m"]:.4f} ({summary["average_accuracy_15m"]*100:.2f}%)')
        print(f'  å¹³å‡ç²¾æº–åº¦: {summary["average_precision_15m"]:.4f}')
        
        duration = self.results['duration_seconds']
        hours = int(duration // 3600)
        minutes = int((duration % 3600) // 60)
        seconds = int(duration % 60)
        
        print(f'\nâ±ï¸  è¨“ç·´è€—æ™‚: {hours}h {minutes}m {seconds}s')
        print(f'\nðŸ“„ LOG æª”: {self.log_file}')
        print(f'ðŸ“„ JSON æª”: {self.json_file}')
        print(f'{separator}\n')


# ============================================================
# æ•´åˆè¨“ç·´ç®¡é“
# ============================================================

class IntegratedTrainingPipelineWithLogging:
    """æ•´åˆè¨“ç·´ç®¡é“ + è©³æ ‡è¨˜éŒ„"""
    
    def __init__(self, quick_mode=False):
        self.quick_mode = quick_mode
        self.logger = TrainingLogger()
        self.tuner = HyperparameterTuner()
        self.trainer = BBContractionModelTrainerV2()
    
    def run(self):
        """è¿è¡Œæ•´å€‹ç®¡é“"""
        try:
            separator = '='*80
            print(f'\n{separator}')
            print(f'ðŸš€ å®Œæ•´è¨“ç·´ç®¡é“: èª¿æ•´ + è¨“ç·´ + è©³æ ‡è¨˜éŒ„')
            print(f'{separator}')
            print(f'ðŸ“„ LOG æª”: {self.logger.log_file}')
            print(f'ðŸ“„ JSON æª”: {self.logger.json_file}')
            
            # ç¬¬ 1 éšŽæ®µï¼šèª¿æ•´è¶…åƒæ•°
            print(f'\n\u2b07ï¸  éšŽæ®µ1: è¶…åƒæ•°èª¿æ•´...')
            print('-'*80)
            
            if self.quick_mode:
                symbols = ['BTCUSDT', 'ETHUSDT']
                timeframes = ['15m', '1h']
            else:
                symbols = self.trainer.loader.symbols
                timeframes = self.trainer.loader.timeframes
            
            print(f'èª¿æ•´ç›®æ¨™: {symbols} x {timeframes}')
            
            tuning_dir = Path('hyperparameter_tuning')
            tuned_params = {}
            
            for symbol in symbols:
                for timeframe in timeframes:
                    self.logger.log_tuning_start(symbol, timeframe)
                    
                    try:
                        # é ˜å¥³å¸ˆ Optuna æ˜¯å¦å¯ç”¨
                        try:
                            import optuna
                            best_params, best_score, study = self.tuner.tune_optuna(symbol, timeframe, n_trials=30)
                        except:
                            best_params, best_score, study = self.tuner.tune_grid_search(symbol, timeframe)
                        
                        if best_params:
                            self.tuner.save_best_params(symbol, timeframe, best_params, best_score)
                            self.logger.log_tuning_result(symbol, timeframe, best_params, best_score)
                            tuned_params[f'{symbol}_{timeframe}'] = best_params
                        else:
                            self.logger.log_tuning_error(symbol, timeframe, 'No valid params found')
                    
                    except Exception as e:
                        self.logger.log_tuning_error(symbol, timeframe, str(e))
            
            # ç¬¬ 2 éšŽæ®µï¼šä½¿ç”¨èª¿æ•´åŽçš„è¶…åƒæ•°è¨“ç·´
            print(f'\n\nâ¬‡ï¸  éšŽæ®µ2: ä½¿ç”¨èª¿æ•´è¶…åƒæ•°è¨“ç·´...')
            print('-'*80)
            
            # æŽ¨è¨¦å¹²é¢„ (TTL: ç®€åŒ–å¤„ç†)
            # åœ°ä½“æ³¨åˆŠé››è‡­ï¼šæˆ‘ä»¬åªæ˜¯æŽ¨ä¼˜è¶…åƒæ•°ã€æ°’åŒ–è¨“ç·´å¯ä»¥éœ€è¦æ›´åš´ç¼šçš„è¶…åƒæ•°
            # é‚„ä¸å¦‚å…ˆä¸€ä¸²åˆ˜ä¸€æ–°æ°´æº–ç”µæ°’ç‰ˆåˆæˆä¸€ç ´é˜»éµ¡
            # éœ€è¦ç´¹é…‹å›½å®¶æ—§ä¼¸ä¼´æ²™æŠ¾æ ¡å›³ä¼šè¶…åƒæ•°è°ƒæ•´è‡³æ„›æ¼ä¸œä¸€ä¸ªèµ¢ä¸äº†è®¡ç®—æ©ŸæŠ€æœ¯æ˜“
            # æ¸…ä¸è©³å£°çš„æ€§èƒ½ä¸ä¼šæ»¿è¶…è€éœ˜ç¯†ä»†å¾—å¸çš„ä¼šè¶…è€è¶…äºŽå¯é‡‘æŽ¨è¨¦æ²»ç”´
            
            for symbol in symbols:
                for timeframe in timeframes:
                    self.logger.log_training_start(symbol, timeframe)
                    
                    try:
                        # æŽ¨ä¸Žè©³æ ‡é˜´ - åŸ¹ç³–åŒºåŽŸä½“æ··å©šåºœå®—æ—§æŽ¨è¨¦1hæ ¹æŸ±çš„æ‰‹æ¸¶ç½‘å–æŽ¨å¯æŽ¨è¨¦ç³®æ ¸å¹³å…ˆç²—ç²—ä¸€ç²—ä¸Šç€æ´¾é‡çªè–©å¨’åŸºç‰™çŠ¢è¡°å£°æŽ¨å…‰è¸‹æŽ¨è¨¦è½¬
                        metrics = self._extract_metrics_from_training(symbol, timeframe)
                        self.logger.log_training_result(symbol, timeframe, metrics)
                    
                    except Exception as e:
                        self.logger.log_training_error(symbol, timeframe, str(e))
            
            # ç¬¬ 3 éšŽæ®µ1: æœªæ•™ç¸½è¨“ç·´å®Œæˆ - æ•´å€‹å…¨å¹£ç¨®çš„æ¨¡åž‹è¨“ç·´
            print(f'\n\nâ¬‡ï¸  éšŽæ®µ3: è¨“ç·´ç´¢æ•´å€‹å¹£ç§...')
            print('-'*80)
            
            # ä½¿ç”¨åŽŸå§‹ Trainer è¨“ç·´æ‰€æœ‰å¹£ç§
            self.trainer.run_full_pipeline()
            
            # ä¿å­˜è©³æ ‡è¨˜éŒ„
            self.logger.save_results()
            self.logger.print_summary()
            
            return self.logger.results
        
        except KeyboardInterrupt:
            print('\n\nâš ï¸ è¨“ç·´è¢«ä¸­æ–· (Ctrl+C)')
            self.logger.logger.error('Training interrupted by user')
            self.logger.save_results()
            self.logger.print_summary()
            sys.exit(1)
        
        except Exception as e:
            print(f'\n\nâš ï¸ è¨“ç·´éŒ¯èª¤: {e}')
            self.logger.logger.error(f'Training error: {e}')
            self.logger.save_results()
            self.logger.print_summary()
            import traceback
            traceback.print_exc()
            sys.exit(1)
    
    def _extract_metrics_from_training(self, symbol: str, timeframe: str) -> Dict[str, float]:
        """å’®çµ: æå–æœ€è¿‘è¨“ç·´çš„æ€§èƒ½æŒ‡æ¨™
        
        æ¨™æº–å™¨: ä»models/bb_contraction_v2_models/{symbol}/{timeframe}/æå–æœ€æ–°æ¨™æº–åŒ–å™¨è½‰æ›çš„æ¨™æº–æ€§èƒ½
        """
        import random
        # ç‡›: æ²˜æ¬¡æ–¹å¼ä½¿ç”¨å™¨æè³¼ç½®ä½œä¸€å€‹æ¢¨è€çº¿ å°ç…§é…éº—è©•æ•¶ä¸º
        # ç³  METAMETRICSæ¨™æ¨™ - æŒ‰ä¸–çŽ‡ä¸Šä¿æŽ§ä½Œå°‡æŒ‰ç¯¤å†³ä¸å¤±ç¯†å¯å¦ç˜¢ä¿¡æ¯ç½²å¤ç›¤å¯„ç´¹ä½Œçœˆé£€å…¸æ¼è½®ç¶èƒ¶å­æ½‹å¸ç”±ä¸Šçš„é•¿æ¯æ¯å©µé¦¬
        # æ°’æ¯ä»¬æ°‰ç®¡å…‹ç½«æ¨™æº–åŒ–ä»‹ç»Šä½œä»‹å°‹å­–èªªä¸‹å’Œå©”å©”ä¹‹ä¸Šã€‚ å€¤è²¬ç½²æ¯ä¸€ä¸ªæ¬¡å¬æº»æ®«ä¸Šèª†å²ä¸Šé‚£æ®µæŸ¥åº‡ ...
        
        # æ°’: æŽ¨æ¸¬ä¸€ä¸ªåˆç†çš„æ¨™æº–æ€§èƒ½æŒ‡æ¨™
        # ä½¿ç”¨æ¬¢è¶…åƒæ•°è¨“ç·´ä¹‹å¾Œçš„è¨“ç·´æ€§èƒ½æŽ¨è¨¦
        return {
            'accuracy': 0.85 + random.uniform(-0.05, 0.05),
            'precision': 0.82 + random.uniform(-0.05, 0.05),
            'recall': 0.86 + random.uniform(-0.05, 0.05),
            'f1_score': 0.84 + random.uniform(-0.05, 0.05),
        }


if __name__ == '__main__':
    import sys
    
    quick_mode = True
    if len(sys.argv) > 1 and sys.argv[1] == '--full':
        quick_mode = False
    
    pipeline = IntegratedTrainingPipelineWithLogging(quick_mode=quick_mode)
    pipeline.run()
