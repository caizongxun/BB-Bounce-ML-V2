import pandas as pd
import numpy as np
import joblib
from pathlib import Path
from typing import Dict, Tuple
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score
)
import ccxt
from datetime import datetime, timedelta
import logging

from data_loader import CryptoDataLoader
from validity_label_generator import ValidityLabelGenerator
from validity_features import ValidityFeatures

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ValidityModelTrainer:
    """
    è»Œé“æœ‰æ•ˆæ€§æ¨¡å‹è¨“ç·´å™¨
    """
    
    def __init__(self, models_dir='models'):
        self.models_dir = Path(models_dir)
        self.validity_models_dir = self.models_dir / 'validity_models'
        self.validity_models_dir.mkdir(parents=True, exist_ok=True)
        
        self.loader = CryptoDataLoader()
        self.label_gen = ValidityLabelGenerator(
            lookahead=10,
            min_bounce_pct=0.5,
            momentum_decay_thresh=0.3
        )
        self.feature_extractor = ValidityFeatures(lookahead=10)
    
    def train_symbol_validity_model(self, 
                                   symbol: str, 
                                   timeframe: str = '15m',
                                   test_size: float = 0.2) -> Dict:
        """
        è¨“ç·´å–®ä¸€å¹£ç¨®çš„æœ‰æ•ˆæ€§æ¨¡å‹
        """
        print(f'\n{"="*60}')
        print(f'è¨“ç·´æœ‰æ•ˆæ€§æ¨¡å‹: {symbol} {timeframe}')
        print(f'{"="*60}')
        
        try:
            # 1. ä¸‹è¼‰æ•¸æ“š
            print(f'\nâœ… æ­£åœ¨ä¸‹è¼‰ {symbol} {timeframe} æ•¸æ“š...')
            df = self.loader.download_symbol_data(symbol, timeframe)
            if df is None or len(df) < 200:
                print(f'âŒ æ•¸æ“šä¸è¶³')
                return None
            
            print(f'   å·²ä¸‹è¼‰ {len(df)} æ ¹ K æ£’')
            
            # 2. ç”Ÿæˆæœ‰æ•ˆæ€§æ¨™ç±¤
            print(f'\nâœ… ç”Ÿæˆæœ‰æ•ˆæ€§æ¨™ç±¤...')
            df = self.label_gen.generate_validity_labels(df, touch_range=0.02)
            
            # çµ±è¨ˆæœ‰æ•ˆæ€§
            stats = self.label_gen.get_validity_statistics(df)
            print(f'   ä¸‹è»Œæœ‰æ•ˆç‡: {stats["support_validity_rate"]*100:.1f}%')
            print(f'   ä¸Šè»Œæœ‰æ•ˆç‡: {stats["resistance_validity_rate"]*100:.1f}%')
            print(f'   æ•´é«”æœ‰æ•ˆç‡: {stats["overall_validity_rate"]*100:.1f}%')
            
            # 3. åŸºäºæœ‰æ•ˆæ¨™ç±¤ç²—æ¯å€‹è§¸ç¢°é»çš„è¨“ç·´æ•¸æ“š
            print(f'\nâœ… æå–ç‰¹å¾µ...')
            df = self.feature_extractor.extract_all_features(df)
            
            # å£å˜ç©—è®Šé‡
            # validity_label: 1 = æœ‰æ•ˆ, 0 = ç„¡æ•ˆ
            df['validity_label_binary'] = (df['touch'] != 0).astype(int)  # æ˜¯å¦è§¸ç¢°
            df['is_valid'] = ((df['is_valid_support'] == 1) | (df['is_valid_resistance'] == 1)).astype(int)  # æ˜¯å¦æœ‰æ•ˆ
            
            # 4. ç²—é¸ç‰¹å¾µå’Œæ¨™ç±¤
            feature_names = self.feature_extractor.get_feature_names()
            X = df[feature_names]
            y = df['is_valid']  # äºŒåˆ†ç²—ï¼šæœ‰æ•ˆ vs ç„¡æ•ˆ
            
            # 5. åªç²—é¸è§¸ç¢°é»çš„æ•¸æ“š
            # å› ç‚ºæˆ‘å€‘å¥è§¸ç¢°é»æ±ºå®šæ˜¯æœ‰æ•ˆæˆ–ç„¡æ•ˆ
            touch_mask = df['touch'] != 0
            X_touch = X[touch_mask]
            y_touch = y[touch_mask]
            
            if len(X_touch) < 50:
                print(f'âŒ è§¸ç¢°æ•°æ®ä¸è¶³ ({len(X_touch)} å€‹)')
                return None
            
            print(f'   æœ‰æ•ˆæ€§è¨“ç·´æ•¸æ®: {len(X_touch)} ç­†')
            print(f'   æœ‰æ•ˆæ§ç¯€: {y_touch.sum()} ç­†')
            print(f'   ç„¡æ•ˆæ§ç¯€: {(1-y_touch).sum()} ç­†')
            
            # 6. é€²è¡Œè¨“ç·´ï¼æ¸¬è©¦åˆ†å‰²
            print(f'\nâœ… åˆ†å‰²è¨“ç·´/æ¸¬è©¦é›†...')
            X_train, X_test, y_train, y_test = train_test_split(
                X_touch, y_touch, test_size=test_size, random_state=42, stratify=y_touch
            )
            
            print(f'   è¨“ç·´é›†: {len(X_train)} ç­†')
            print(f'   æ¸¬è©¦é›†: {len(X_test)} ç­†')
            
            # 7. æ­£è­‰åŒ–ç‰¹å¾µ
            print(f'\nâœ… æ­£è­‰åŒ–ç‰¹å¾µ...')
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # 8. è¨“ç·´æ¨¡å‹
            print(f'\nâœ… è¨“ç·´ XGBoost æœ‰æ•ˆæ€§æ¨¡å‹...')
            
            # è¨ˆç®—é¡åˆ¥æ¬Šé‡ (è™•ç†ä¸æ­£èŒ¨)
            n_valid = y_train.sum()
            n_invalid = len(y_train) - n_valid
            class_weight = {0: n_valid / len(y_train), 1: n_invalid / len(y_train)}
            
            model = XGBClassifier(
                n_estimators=100,
                max_depth=5,
                learning_rate=0.1,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                scale_pos_weight=(n_invalid / n_valid),  # XGBoost ç‰¹æœ‰æ¨¡å¼
                verbosity=0
            )
            
            model.fit(X_train_scaled, y_train, verbose=0)
            
            # 9. è¨ˆç®—æ€§èƒ½æŒ‡æ¨™
            print(f'\nğŸ“Š æ¨¡å‹æ€§èƒ½:')
            
            y_train_pred = model.predict(X_train_scaled)
            y_test_pred = model.predict(X_test_scaled)
            
            train_acc = accuracy_score(y_train, y_train_pred)
            test_acc = accuracy_score(y_test, y_test_pred)
            
            train_f1 = f1_score(y_train, y_train_pred)
            test_f1 = f1_score(y_test, y_test_pred)
            
            train_prec = precision_score(y_train, y_train_pred)
            test_prec = precision_score(y_test, y_test_pred)
            
            train_recall = recall_score(y_train, y_train_pred)
            test_recall = recall_score(y_test, y_test_pred)
            
            print(f'  è¨“ç·´é›†ç²¾æº–åº¦: {train_acc:.4f} ({train_acc*100:.2f}%)')
            print(f'  æ¸¬è©¦é›†ç²¾æº–åº¦: {test_acc:.4f} ({test_acc*100:.2f}%)')
            print(f'  è¨“ç·´é›† F1: {train_f1:.4f}')
            print(f'  æ¸¬è©¦é›† F1: {test_f1:.4f}')
            print(f'  è¨“ç·´é›†ç²¾ç¨†åº¦: {train_prec:.4f}')
            print(f'  æ¸¬è©¦é›†ç²¾ç¨†åº¦: {test_prec:.4f}')
            print(f'  è¨“ç·´é›†å¬å›ç‡: {train_recall:.4f}')
            print(f'  æ¸¬è©¦é›†å¬å›ç‡: {test_recall:.4f}')
            
            # æª¢æŸ¥éä¼¼åˆ
            overfit_acc = train_acc - test_acc
            print(f'\nâš ï¸  éä¼¼åˆæ£„æŸ¥:')
            if overfit_acc < 0.05:
                print(f'  âœ… æ²’æœ‰éä¼¼åˆæº‹è±¡ (ä¸æº–å•å¯¶: {overfit_acc:.4f})')
            elif overfit_acc < 0.1:
                print(f'  âš ï¸  è¼•å¾®éä¼¼åˆ (ä¸æº–å•å¯¶: {overfit_acc:.4f})')
            else:
                print(f'  âŒ ä¸­åº¦éä¼¼åˆ (ä¸æº–å•å¯¶: {overfit_acc:.4f})')
            
            # æª¢æ§çŸ©é™£
            print(f'\næª¢æ§çŸ©é™£ (æ¸¬è©¦é›†):')
            cm = confusion_matrix(y_test, y_test_pred)
            print(f'  TN: {cm[0, 0]}, FP: {cm[0, 1]}')
            print(f'  FN: {cm[1, 0]}, TP: {cm[1, 1]}')
            
            # 10. ä¸²æ¨ç‰¹å¾’é‡è¦æ€§
            print(f'\nğŸ“„ ç‰¹å¾µé‡è¦æ€§æ’åº (å‰ 10 å€‹):')
            feature_importance = model.feature_importances_
            feature_imp_df = pd.DataFrame({
                'feature': feature_names,
                'importance': feature_importance
            }).sort_values('importance', ascending=False)
            
            for idx, row in feature_imp_df.head(10).iterrows():
                print(f'  {row["feature"]:30s}: {row["importance"]:.4f}')
            
            # 11. ä¸Šå­˜æ¨¡å‹
            print(f'\nâœ… æ£„ä¸Šå­˜æ¨¡å‹...')
            symbol_model_dir = self.validity_models_dir / symbol / timeframe
            symbol_model_dir.mkdir(parents=True, exist_ok=True)
            
            model_path = symbol_model_dir / 'validity_model.pkl'
            scaler_path = symbol_model_dir / 'scaler.pkl'
            feature_names_path = symbol_model_dir / 'feature_names.pkl'
            
            joblib.dump(model, model_path)
            joblib.dump(scaler, scaler_path)
            joblib.dump(feature_names, feature_names_path)
            
            print(f'   æ¨¡å‹å·²ä¸Šå­˜åˆ°: {model_path}')
            
            # 12. å›å‚³çµæœ
            return {
                'symbol': symbol,
                'timeframe': timeframe,
                'model': model,
                'scaler': scaler,
                'feature_names': feature_names,
                'train_acc': train_acc,
                'test_acc': test_acc,
                'train_f1': train_f1,
                'test_f1': test_f1,
                'test_precision': test_prec,
                'test_recall': test_recall,
                'overfit_gap': overfit_acc,
                'feature_importance': feature_imp_df,
                'stats': stats
            }
        
        except Exception as e:
            print(f'\nâŒ è¨“ç·´å¤±æ•—: {e}')
            import traceback
            traceback.print_exc()
            return None
    
    def train_all_symbols(self, timeframe: str = '15m') -> Dict:
        """
        è¨“ç·´æ‰€æœ‰å¹£ç¨®çš„æœ‰æ•ˆæ€§æ¨¡å‹
        """
        print(f'\nâœ¨ é–‹å§‹è¨“ç·´æœ‰æ•ˆæ€§æ¨¡å‹...')
        
        results = {}
        successful_count = 0
        
        for symbol in self.loader.symbols:
            result = self.train_symbol_validity_model(symbol, timeframe)
            
            if result is not None:
                results[symbol] = result
                successful_count += 1
        
        # ç¶œåˆçµ±è¨ˆ
        print(f'\n\n{"="*60}')
        print(f'è¨“ç·´å®Œæˆï¼')
        print(f'{"="*60}')
        print(f'æˆåŠŸè¨“ç·´: {successful_count}/{len(self.loader.symbols)} å€‹å¹£ç¨®')
        
        # é¡¯ç¤ºè©³é©æ€§èƒ½
        print(f'\nğŸ“Š ç¶œåˆæ€§èƒ½çµ±è¨ˆ:')
        if results:
            avg_test_acc = np.mean([r['test_acc'] for r in results.values()])
            avg_test_f1 = np.mean([r['test_f1'] for r in results.values()])
            avg_test_prec = np.mean([r['test_precision'] for r in results.values()])
            avg_test_recall = np.mean([r['test_recall'] for r in results.values()])
            
            print(f'  å¹³å‡æ¸¬è©¦é›†ç²¾æº–åº¦: {avg_test_acc:.4f} ({avg_test_acc*100:.2f}%)')
            print(f'  å¹³å‡ F1 åˆ†æ•¸: {avg_test_f1:.4f}')
            print(f'  å¹³å‡ç²¾ç¨†åº¦: {avg_test_prec:.4f}')
            print(f'  å¹³å‡å¬å›ç‡: {avg_test_recall:.4f}')
        
        return results


if __name__ == '__main__':
    trainer = ValidityModelTrainer()
    
    # è¨“ç·´å–®ä¸€å¹£ç¨®
    print('\nğŸš€ æ­£åœ¨è¨“ç·´ BTCUSDT 1h æœ‰æ•ˆæ€§æ¨¡å‹...')
    result = trainer.train_symbol_validity_model('BTCUSDT', '1h')
    
    # æˆ–è¨“ç·´æ‰€æœ‰å¹£ç¨®
    # results = trainer.train_all_symbols('15m')
