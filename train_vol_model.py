import pandas as pd
import numpy as np
from pathlib import Path
import joblib
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, classification_report, accuracy_score
from xgboost import XGBRegressor, XGBClassifier
import warnings

warnings.filterwarnings('ignore')

from data_loader import CryptoDataLoader
from label_generator import LabelGenerator

class VolatilityModelTrainer:
    def __init__(self, output_dir='models'):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç‚ºæ¯å€‹å¹£ç¨® + timeframe å»ºç«‹ç›®éŒ„
        self.models_base_dir = self.output_dir / 'vol_models'
        self.models_base_dir.mkdir(parents=True, exist_ok=True)
        
        self.loader = CryptoDataLoader()
        self.generator = LabelGenerator(period=20, std_dev=2)
    
    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ç”¢ç”¢æ³¢å‹•æ€§é æ¸¬ç‰¹å½•
        """
        df = df.copy()
        close_col = 'close' if 'close' in df.columns else 'Close'
        
        # åŸºç¤ OHLCV
        if 'open' not in df.columns and 'Open' in df.columns:
            df['open'] = df['Open']
            df['high'] = df['High']
            df['low'] = df['Low']
        
        # 1. ç•¶å‰æ³¢å‹•æ€§
        df['volatility'] = df['volatility'].fillna(df['volatility'].mean())
        
        # 2. ä¸Šä¸‹è»Œå¯¶äºˆ (BBW)
        df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle']
        
        # 3. åƒ¹æ ¼è»Šç¾ªç‡è¼•æ¸£
        df['price_range'] = (df['high'] - df['low']) / df[close_col] if 'high' in df.columns else 0
        df['body_size'] = (df[close_col] - df['open']).abs() / df[close_col] if 'open' in df.columns else 0
        
        # 4. RSI å’Œ æ³¢å‹•æ€§è´Šé‡
        df = self.calculate_rsi(df)
        df['volume_change'] = df['volume'].pct_change().rolling(window=5).std() if 'volume' in df.columns else 0
        
        # 5. å¹³å‡çœŸå¯¶è­ åœ°åŒºé–“
        df['atr_14'] = self.calculate_atr(df, period=14)
        df['atr_ratio'] = df['atr_14'] / df[close_col]
        
        # 6. åƒ¹æ ¼è·¯èµ°çš„èººåº¦
        df['returns'] = df[close_col].pct_change()
        df['returns_rolling_std'] = df['returns'].rolling(window=10).std()
        df['returns_rolling_mean'] = df['returns'].rolling(window=10).mean()
        
        # 7. æ­·å²æ³¢å‹•æ€§ (Historical Volatility)
        df['hist_vol_5'] = df[close_col].pct_change().rolling(window=5).std()
        df['hist_vol_10'] = df[close_col].pct_change().rolling(window=10).std()
        df['hist_vol_20'] = df[close_col].pct_change().rolling(window=20).std()
        
        # 8. ä¸‰ç¨€ç·š
        df['sma_5'] = df[close_col].rolling(window=5).mean()
        df['sma_20'] = df[close_col].rolling(window=20).mean()
        df['price_to_sma'] = df[close_col] / df['sma_20']
        
        # 9. ç¢© (Stochastic)
        df = self.calculate_stochastic(df)
        
        # å¡«ä»… NaN
        df = df.fillna(method='bfill').fillna(method='ffill')
        
        return df
    
    def calculate_rsi(self, df: pd.DataFrame, period=14) -> pd.DataFrame:
        """
        è¨ˆç®— RSI
        """
        df = df.copy()
        close_col = 'close' if 'close' in df.columns else 'Close'
        
        delta = df[close_col].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        df['rsi'] = df['rsi'].fillna(50)
        
        return df
    
    def calculate_atr(self, df: pd.DataFrame, period=14) -> pd.Series:
        """
        è¨ˆç®— ATR (Average True Range)
        """
        close_col = 'close' if 'close' in df.columns else 'Close'
        
        high = df['high'] if 'high' in df.columns else df[close_col]
        low = df['low'] if 'low' in df.columns else df[close_col]
        
        tr1 = high - low
        tr2 = (high - df[close_col].shift()).abs()
        tr3 = (low - df[close_col].shift()).abs()
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        atr = tr.rolling(window=period).mean()
        
        return atr
    
    def calculate_stochastic(self, df: pd.DataFrame, period=14) -> pd.DataFrame:
        """
        è¨ˆç®—ä½µç¨€ç·‘ç·š
        """
        df = df.copy()
        
        high = df['high'] if 'high' in df.columns else df['close']
        low = df['low'] if 'low' in df.columns else df['close']
        close_col = 'close' if 'close' in df.columns else 'Close'
        
        min_low = low.rolling(window=period).min()
        max_high = high.rolling(window=period).max()
        
        df['k_percent'] = 100 * ((df[close_col] - min_low) / (max_high - min_low))
        df['d_percent'] = df['k_percent'].rolling(window=3).mean()
        
        return df
    
    def train_single_symbol(self, symbol: str, timeframe: str, touch_range=0.02, test_size=0.2, model_type='regression'):
        """
        ç‚ºå–®å€‹å¹£ç¨® + timeframe è¨“ç·´æ³¢å‹•æ€§æ¨¡å‹
        
        model_type: 'regression' æˆ– 'classification'
        """
        print(f'\n{"="*60}')
        print(f'ğŸ“š è¨“ç·´ {symbol} {timeframe} æ³¢å‹•æ€§æ¨¡å‹ ({model_type})')
        print(f'{"="*60}')
        
        try:
            # 1. ä¸‹è¼‰æ•¸æ“š
            df = self.loader.download_symbol_data(symbol, timeframe)
            if df is None:
                print(f'âŒ {symbol} {timeframe} ä¸‹è¼‰å¤±æ•—')
                return False
            
            # 2. ç”¢ç”Ÿæ¨™ç±¤
            print(f'ğŸ”§ ç”¢ç”Ÿæ¨™ç±¤...')
            df = self.generator.create_training_dataset(df, lookahead=5, touch_range=touch_range)
            
            # 3. ç”¢ç”¢ç‰¹å½•
            print(f'ğŸ”§ ç”¢ç”¢ç‰¹å½•...')
            df = self.create_features(df)
            
            # 4. é¸æ“‡ç‰¹å½•
            feature_cols = [
                'volatility', 'bb_width', 'price_range', 'body_size',
                'rsi', 'volume_change', 'atr_ratio',
                'returns_rolling_std', 'returns_rolling_mean',
                'hist_vol_5', 'hist_vol_10', 'hist_vol_20',
                'price_to_sma', 'k_percent', 'd_percent'
            ]
            
            X = df[feature_cols].fillna(method='ffill').fillna(method='bfill')
            
            if model_type == 'regression':
                y = df['future_volatility']
                y = y[y.notna()]
                X = X.loc[y.index]
            else:  # classification
                y = df['volatility_numeric']
            
            # 5. åˆ†å‰²è¨“ç·´/æ¸¬è©¦é›†
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42
            )
            
            print(f'  è¨“ç·´é›†: {len(X_train)} æ ¹')
            print(f'  æ¸¬è©¦é›†: {len(X_test)} æ ¹')
            
            # 6. è¨“ç·´æ¨¡å‹
            print(f'ğŸ“š è¨“ç·´æ¨¡å‹...')
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            if model_type == 'regression':
                model = XGBRegressor(
                    n_estimators=100,
                    max_depth=6,
                    learning_rate=0.1,
                    subsample=0.8,
                    colsample_bytree=0.8,
                    random_state=42,
                    verbosity=0
                )
                model.fit(X_train_scaled, y_train.values)
                
                # é©—è­‰
                y_pred = model.predict(X_test_scaled)
                mse = mean_squared_error(y_test, y_pred)
                rmse = np.sqrt(mse)
                mae = mean_absolute_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred)
                
                print(f'  MSE: {mse:.6f}')
                print(f'  RMSE: {rmse:.6f}')
                print(f'  MAE: {mae:.6f}')
                print(f'  RÂ²: {r2:.4f}')
            else:
                model = XGBClassifier(
                    n_estimators=100,
                    max_depth=6,
                    learning_rate=0.1,
                    subsample=0.8,
                    colsample_bytree=0.8,
                    random_state=42,
                    eval_metric='mlogloss',
                    verbosity=0,
                    num_class=3
                )
                model.fit(X_train_scaled, y_train.values)
                
                # é©—è­‰
                y_pred = model.predict(X_test_scaled)
                acc = accuracy_score(y_test, y_pred)
                
                print(f'  ä¸Šä½œ: {acc:.4f}')
                print(f'\nåˆ†é¡å ±å‘Šï¼š')
                label_names = ['ä½æ³¢', 'ä¸­æ³¢', 'é«˜æ³¢']
                print(classification_report(y_test, y_pred, target_names=label_names))
            
            # 7. ä¿å­˜æ¨¡å‹
            symbol_dir = self.models_base_dir / symbol / timeframe
            symbol_dir.mkdir(parents=True, exist_ok=True)
            
            model_path = symbol_dir / f'model_{model_type}.pkl'
            scaler_path = symbol_dir / f'scaler_{model_type}.pkl'
            
            joblib.dump(model, model_path)
            joblib.dump(scaler, scaler_path)
            
            print(f'\nğŸ“¦ æ¨¡å‹å·²ä¿å­˜:')
            print(f'  {model_path}')
            print(f'  {scaler_path}')
            
            return True
        
        except Exception as e:
            print(f'âŒ è¨“ç·´å¤±æ•—: {e}')
            return False
    
    def run_full_pipeline(self, touch_range=0.02, test_size=0.2, model_type='regression'):
        """
        ç‚ºæ‰€æœ‰å¹£ç¨® + timeframe è¨“ç·´æ³¢å‹•æ€§æ¨¡å‹
        """
        print(f'\nğŸš€ é–‹å§‹ç‚ºæ‰€æœ‰å¹£ç¨®è¨“ç·´{model_type}æ³¢å‹•æ€§æ¨¡å‹...')
        
        success_count = 0
        total_count = len(self.loader.symbols) * len(self.loader.timeframes)
        
        for symbol in self.loader.symbols:
            for timeframe in self.loader.timeframes:
                if self.train_single_symbol(symbol, timeframe, touch_range, test_size, model_type):
                    success_count += 1
        
        print(f'\n{"="*60}')
        print(f'âœ… è¨“ç·´å®Œæˆï¼æˆåŠŸ: {success_count}/{total_count}')
        print(f'{"="*60}')
        print(f'æ¨¡å‹ä¿å­˜ä½ç½®: {self.models_base_dir}')
        print(f'çµæ§‹ï¼šmodels/vol_models/<SYMBOL>/<TIMEFRAME>/')


if __name__ == '__main__':
    # è¨“ç·´å›æ­¸æ¨¡å¼ï¼ˆé æ¸¬æ³¢å‹•æ€§æ•¸å€¼ï¼‰
    trainer = VolatilityModelTrainer()
    trainer.run_full_pipeline(touch_range=0.02, test_size=0.2, model_type='regression')
    
    # è¨“ç·´åˆ†é¡æ¨¡å¼ï¼ˆä½/ä¸­/é«˜ï¼‰
    # trainer2 = VolatilityModelTrainer()
    # trainer2.run_full_pipeline(touch_range=0.02, test_size=0.2, model_type='classification')
