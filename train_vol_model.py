import pandas as pd
import numpy as np
from pathlib import Path
import joblib
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, classification_report, accuracy_score
from xgboost import XGBRegressor, XGBClassifier
import warnings

warnings.filterwarnings('ignore')

from data_loader import CryptoDataLoader
from label_generator import LabelGenerator

class VolatilityModelTrainer:
    def __init__(self, output_dir='models'):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.loader = CryptoDataLoader()
        self.generator = LabelGenerator(period=20, std_dev=2)
        
        self.model = None
        self.scaler = None
    
    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ç”¢ç”¢æ³¢å‹•æ€§é æ¸¬ç‰¹å½›
        """
        df = df.copy()
        close_col = 'close' if 'close' in df.columns else 'Close'
        
        # åŸºç¤ OHLCV
        if 'open' not in df.columns and 'Open' in df.columns:
            df['open'] = df['Open']
            df['high'] = df['High']
            df['low'] = df['Low']
        
        # 1. ç•¶å‰æ³¢å‹•æ€§
        df['volatility'] = df['volatility'].fillna(df['volatility'].mean())
        
        # 2. ä¸Šä¸‹è»Œå¯¶äºˆ (BBW)
        df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle']
        
        # 3. åƒ¹æ ¼è»Šç¾ªç‡è¼•æ¸¥
        df['price_range'] = (df['high'] - df['low']) / df[close_col] if 'high' in df.columns else 0
        df['body_size'] = (df[close_col] - df['open']).abs() / df[close_col] if 'open' in df.columns else 0
        
        # 4. RSI å’Œ å‹˜å‹•æ€§ç¬¬ (Volume Volatility)
        df = self.calculate_rsi(df)
        df['volume_change'] = df['volume'].pct_change().rolling(window=5).std() if 'volume' in df.columns else 0
        
        # 5. å¹³å‡åƒ…æ„Ÿè­ åœ°åŒºé–“
        df['atr_14'] = self.calculate_atr(df, period=14)
        df['atr_ratio'] = df['atr_14'] / df[close_col]
        
        # 6. åƒ¹æ ¼è·¯æ—çš„è°ºåº¦
        df['returns'] = df[close_col].pct_change()
        df['returns_rolling_std'] = df['returns'].rolling(window=10).std()
        df['returns_rolling_mean'] = df['returns'].rolling(window=10).mean()
        
        # 7. æ­·å²æ³¢å‹•æ€§ (Historical Volatility)
        df['hist_vol_5'] = df[close_col].pct_change().rolling(window=5).std()
        df['hist_vol_10'] = df[close_col].pct_change().rolling(window=10).std()
        df['hist_vol_20'] = df[close_col].pct_change().rolling(window=20).std()
        
        # 8. ä¸‰ç¨€ç·š
        df['sma_5'] = df[close_col].rolling(window=5).mean()
        df['sma_20'] = df[close_col].rolling(window=20).mean()
        df['price_to_sma'] = df[close_col] / df['sma_20']
        
        # 9. ç¢© (Stochastic)
        df = self.calculate_stochastic(df)
        
        # å¡«ä»… NaN
        df = df.fillna(method='bfill').fillna(method='ffill')
        
        return df
    
    def calculate_rsi(self, df: pd.DataFrame, period=14) -> pd.DataFrame:
        """
        è¨ˆç®— RSI
        """
        df = df.copy()
        close_col = 'close' if 'close' in df.columns else 'Close'
        
        delta = df[close_col].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        df['rsi'] = df['rsi'].fillna(50)
        
        return df
    
    def calculate_atr(self, df: pd.DataFrame, period=14) -> pd.Series:
        """
        è¨ˆç®— ATR (Average True Range)
        """
        close_col = 'close' if 'close' in df.columns else 'Close'
        
        high = df['high'] if 'high' in df.columns else df[close_col]
        low = df['low'] if 'low' in df.columns else df[close_col]
        
        tr1 = high - low
        tr2 = (high - df[close_col].shift()).abs()
        tr3 = (low - df[close_col].shift()).abs()
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        atr = tr.rolling(window=period).mean()
        
        return atr
    
    def calculate_stochastic(self, df: pd.DataFrame, period=14) -> pd.DataFrame:
        """
        è¨ˆç®—ä½µç¨€ç·‘ç·š
        """
        df = df.copy()
        
        high = df['high'] if 'high' in df.columns else df['close']
        low = df['low'] if 'low' in df.columns else df['close']
        close_col = 'close' if 'close' in df.columns else 'Close'
        
        min_low = low.rolling(window=period).min()
        max_high = high.rolling(window=period).max()
        
        df['k_percent'] = 100 * ((df[close_col] - min_low) / (max_high - min_low))
        df['d_percent'] = df['k_percent'].rolling(window=3).mean()
        
        return df
    
    def load_and_prepare_data(self, touch_range=0.02):
        """
        åŠ è¼‰ã€æ•´ç†è¨“ç·´æ•¸æ“š
        """
        print('ğŸš€ é–‹å§‹ä¸‹è¼‰æ•´ç†è¨“ç·´æ•¸æ“š...')
        
        all_dfs = []
        
        for symbol in self.loader.symbols:
            try:
                print(f'  â¬‡ï¸  {symbol}...', end=' ', flush=True)
                
                symbol_dfs = []
                for tf in self.loader.timeframes:
                    df = self.loader.download_symbol_data(symbol, tf)
                    if df is not None:
                        # ç”¢ç”Ÿæ¨™ç±¤
                        df = self.generator.create_training_dataset(df, lookahead=5, touch_range=touch_range)
                        df['symbol'] = symbol
                        df['timeframe'] = tf
                        symbol_dfs.append(df)
                
                if symbol_dfs:
                    combined = pd.concat(symbol_dfs, ignore_index=True)
                    all_dfs.append(combined)
                    print(f'âœ… {len(combined)} æ ¹')
                else:
                    print(f'âŒ')
            
            except Exception as e:
                print(f'âŒ {e}')
        
        if all_dfs:
            full_df = pd.concat(all_dfs, ignore_index=True)
            print(f'\nâœ… æ•´åˆå¾Œ: {len(full_df)} æ ¹è¨“ç·´æ•¸æ“š')
            return full_df
        else:
            raise ValueError('æ²’æœ‰æˆåŠŸåŠ è¼‰ä»»ä½•è¨“ç·´æ•¸æ“š')
    
    def train_regression(self, X_train, y_train, X_test=None, y_test=None):
        """
        è¨“ç·´å›æ­¸æ¨¡å¼ï¼ˆé æ¸¬æœªä¾†æ³¢å‹•æ€§æ•¸å€¼ï¼‰
        """
        print(f'\nğŸ“š è¨“ç·´æ³¢å‹•æ€§å›æ­¸é æ¸¬æ¨¡å‹...')
        
        self.scaler = StandardScaler()
        X_train_scaled = self.scaler.fit_transform(X_train)
        
        self.model = XGBRegressor(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            verbosity=0
        )
        
        self.model.fit(X_train_scaled, y_train)
        
        if X_test is not None and y_test is not None:
            X_test_scaled = self.scaler.transform(X_test)
            y_pred = self.model.predict(X_test_scaled)
            
            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            
            print(f'  MSE: {mse:.6f}')
            print(f'  RMSE: {rmse:.6f}')
            print(f'  MAE: {mae:.6f}')
            print(f'  RÂ²: {r2:.4f}')
    
    def train_classification(self, X_train, y_train, X_test=None, y_test=None):
        """
        è¨“ç·´åˆ†é¡æ¨¡å¼ï¼ˆä½/ä¸­/é«˜æ³¢å‹•æ€§ï¼‰
        """
        print(f'\nğŸ“š è¨“ç·´æ³¢å‹•æ€§åˆ†é¡æ¨¡å‹...')
        
        self.scaler = StandardScaler()
        X_train_scaled = self.scaler.fit_transform(X_train)
        
        self.model = XGBClassifier(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            eval_metric='mlogloss',
            verbosity=0
        )
        
        self.model.fit(X_train_scaled, y_train)
        
        if X_test is not None and y_test is not None:
            X_test_scaled = self.scaler.transform(X_test)
            y_pred = self.model.predict(X_test_scaled)
            
            acc = accuracy_score(y_test, y_pred)
            
            print(f'  ä¸Šä½œ: {acc:.4f}')
            print(f'\nç®•ç§‘é –æˆ¶è™Ÿè¾²è±¡ï¼š')
            print(classification_report(y_test, y_pred, target_names=['ä½æ³¢', 'ä¸­æ³¢', 'é«˜æ³¢']))
    
    def save_model(self, model_suffix='regression'):
        """
        ä¿å­˜æ¨¡å¼
        """
        model_path = self.output_dir / f'vol_model_{model_suffix}.pkl'
        scaler_path = self.output_dir / f'vol_scaler_{model_suffix}.pkl'
        
        joblib.dump(self.model, model_path)
        joblib.dump(self.scaler, scaler_path)
        
        print(f'\nğŸ’¾ æ¨¡å¼å·²ä¿å­˜:')
        print(f'  {model_path}')
        print(f'  {scaler_path}')
    
    def run_full_pipeline(self, touch_range=0.02, test_size=0.2, model_type='regression'):
        """
        åŸ·è¡Œå®Œæ•´è¨“ç·´æµç¨‹
        
        model_type: 'regression' (é æ¸¬æ³¢å‹•æ€§) æˆ– 'classification' (åˆ†é¡ä½/ä¸­/é«˜)
        """
        # 1. åŠ è¼‰æ•´ç†æ•°æ®
        df = self.load_and_prepare_data(touch_range=touch_range)
        
        # 2. ç”¢ç”¢ç‰¹å½›
        print(f'\nğŸ”§ ç”¢ç”¢ç‰¹å½”...')
        df = self.create_features(df)
        
        # 3. æ²é¸ç‰¹å½›
        feature_cols = [
            'volatility', 'bb_width', 'price_range', 'body_size',
            'rsi', 'volume_change', 'atr_ratio',
            'returns_rolling_std', 'returns_rolling_mean',
            'hist_vol_5', 'hist_vol_10', 'hist_vol_20',
            'price_to_sma', 'k_percent', 'd_percent'
        ]
        
        X = df[feature_cols].fillna(method='ffill').fillna(method='bfill')
        
        if model_type == 'regression':
            y = df['future_volatility']
            y = y[y.notna()]
            X = X.loc[y.index]
        else:  # classification
            y = df['volatility_numeric']
        
        # 4. åˆ†éš”è¨“ç·´/æ¸¬è©¦é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42
        )
        
        print(f'  è¨“ç·´é›†: {len(X_train)} æ ¹')
        print(f'  æ¸¬è©¦é›†: {len(X_test)} æ ¹')
        
        # 5. è¨“ç·´æ¨¡å¼
        if model_type == 'regression':
            self.train_regression(X_train.values, y_train.values, X_test.values, y_test.values)
            self.save_model('regression')
        else:
            self.train_classification(X_train.values, y_train.values, X_test.values, y_test.values)
            self.save_model('classification')
        
        print(f'\nâœ… è¨“ç·´å®Œæˆï¼')


if __name__ == '__main__':
    # è¨“ç·´å›æ­¸æ¨¡å¼ï¼ˆé æ¸¬æ³¢å‹•æ€§æ•¸å€¼ï¼‰
    trainer = VolatilityModelTrainer()
    trainer.run_full_pipeline(touch_range=0.02, test_size=0.2, model_type='regression')
    
    # è¨“ç·´åˆ†é¡æ¨¡å¼ï¼ˆä½/ä¸­/é«˜ï¼‰
    # trainer2 = VolatilityModelTrainer()
    # trainer2.run_full_pipeline(touch_range=0.02, test_size=0.2, model_type='classification')
