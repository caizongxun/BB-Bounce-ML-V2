import pandas as pd
import numpy as np
from pathlib import Path
import joblib
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
from xgboost import XGBClassifier
import warnings

warnings.filterwarnings('ignore')

from data_loader import CryptoDataLoader
from label_generator import LabelGenerator

class BBModelTrainer:
    def __init__(self, output_dir='models'):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç‚ºæ¯å€‹å¹£ç¨® + timeframe å»ºç«‹ç›®éŒ„
        self.models_base_dir = self.output_dir / 'bb_models'
        self.models_base_dir.mkdir(parents=True, exist_ok=True)
        
        self.loader = CryptoDataLoader()
        self.generator = LabelGenerator(period=20, std_dev=2)
        
        # æ¨™ç±¤å°æ‡‰
        self.label_map = {-1: 0, 0: 1, 1: 2}  # support -> 0, neutral -> 1, resistance -> 2
        self.inverse_label_map = {0: -1, 1: 0, 2: 1}
    
    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å¾ K ç·šæ•¸æ“šè£½ä½œç‰¹å½•
        """
        df = df.copy()
        close_col = 'close' if 'close' in df.columns else 'Close'
        
        # åŸºç¤ OHLCV
        if 'open' not in df.columns and 'Open' in df.columns:
            df['open'] = df['Open']
            df['high'] = df['High']
            df['low'] = df['Low']
        
        # 1. åƒ¹æ ¼ä½ç½®ï¼ˆç›¸å°æ–¼ BB ä¸­è»¸ï¼‰
        df['price_to_bb_middle'] = (df[close_col] - df['bb_middle']) / df['bb_middle']
        
        # 2. åƒ¹æ ¼è·é›¢ä¸Š/ä¸‹è»Œ
        df['dist_upper_norm'] = (df['bb_upper'] - df[close_col]) / (df['bb_upper'] - df['bb_lower'])
        df['dist_lower_norm'] = (df[close_col] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])
        
        # 3. BB å¯¶äºˆï¼ˆBBW: Bollinger Bands Widthï¼‰
        df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle']
        
        # 4. RSI
        df = self.calculate_rsi(df)
        
        # 5. æ³¢å‹•æ€§
        df['volatility'] = df['volatility'].fillna(df['volatility'].mean())
        
        # 6. åƒ¹æ ¼å‹•é‡ï¼ˆæ—¥å¹¾ä½•å¹£ç‡ï¼‰
        df['returns'] = df[close_col].pct_change()
        df['returns_std'] = df['returns'].rolling(window=20).std()
        
        # 7. åƒ¹æ ¼èµ°å‹¢
        df['high_low_ratio'] = df['high'] / df['low'] - 1 if 'high' in df.columns else 0
        df['close_open_ratio'] = df[close_col] / df['open'] - 1 if 'open' in df.columns else 0
        
        # 8. ç§»å‹•å¹³å‡
        df['sma_5'] = df[close_col].rolling(window=5).mean()
        df['sma_20'] = df[close_col].rolling(window=20).mean()
        df['sma_50'] = df[close_col].rolling(window=50).mean()
        
        # æ¨£æœ¬æ•¸æ“šæ­£è­‰åŒ–
        df = df.fillna(method='bfill').fillna(method='ffill')
        
        return df
    
    def calculate_rsi(self, df: pd.DataFrame, period=14) -> pd.DataFrame:
        """
        è¨ˆç®— RSI (Relative Strength Index)
        """
        df = df.copy()
        close_col = 'close' if 'close' in df.columns else 'Close'
        
        delta = df[close_col].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        df['rsi'] = df['rsi'].fillna(50)
        
        return df
    
    def check_overfitting(self, train_acc, test_acc):
        """
        æ¤œæŸ¥éæ“šåˆä½ï¼ˆOverfittingï¼‰
        """
        gap = train_acc - test_acc
        
        print(f'\nğŸ” éæ“šåˆä½æ¤œæŸ¥ï¼š')
        print(f'  è¨“ç·´ç²¾æº–åº¦: {train_acc:.4f} ({train_acc*100:.2f}%)')
        print(f'  æ¸¬è©¦ç²¾æº–åº¦: {test_acc:.4f} ({test_acc*100:.2f}%)')
        print(f'  ç²¾æº–åº¦å¯¶: {gap:.4f} ({gap*100:.2f}%)')
        
        if gap < 0.01:  # ç²¾æº–åº¦å¯¶ < 1%
            print(f'  âœ… æ¨¡å‹å¸·è²Œï¼æ²’æœ‰éæ“šåˆä½')
            return 'good'
        elif gap < 0.05:  # ç²¾æº–åº¦å¯¶ < 5%
            print(f'  âš ï¸ è¼•å¾®éæ“šåˆä½ï¼Œä½†å¯ä»¥æ¥å—')
            return 'acceptable'
        elif gap < 0.10:  # ç²¾æº–åº¦å¯¶ < 10%
            print(f'  ğŸ‘ ä¸­ç­‰éæ“šåˆä½ï¼Œbé°§è©°æ£æ®†å»ºè­°æˆå‡º')
            return 'warning'
        else:  # ç²¾æº–åº¦å¯¶ >= 10%
            print(f'  âŒ åš´é‡éæ“šåˆä½ï¼è­°èª®é‡æ–°è¨“ç·´')
            return 'bad'
    
    def train_single_symbol(self, symbol: str, timeframe: str, touch_range=0.02, test_size=0.2):
        """
        ç‚ºå–®å€‹å¹£ç¨® + timeframe è¨“ç·´æ¨¡å‹
        """
        separator = '='*60
        print(f'\n{separator}')
        print(f'ğŸ¯ è¨“ç·´ {symbol} {timeframe} æ¨¡å‹')
        print(f'{separator}')
        
        try:
            # 1. ä¸‹è¼‰æ•¸æ“š
            df = self.loader.download_symbol_data(symbol, timeframe)
            if df is None:
                print(f'âŒ {symbol} {timeframe} ä¸‹è¼‰å¤±æ•—')
                return False
            
            # 2. ç”¢ç”Ÿæ¨™ç±¤
            print(f'ğŸ”§ ç”¢ç”Ÿæ¨™ç±¤...')
            df = self.generator.create_training_dataset(df, lookahead=5, touch_range=touch_range)
            
            # 3. ç”¢ç”¢ç‰¹å½•
            print(f'ğŸ”§ ç”¢ç”¢ç‰¹å½•...')
            df = self.create_features(df)
            
            # 4. é¸æ“‡ç‰¹å½•
            feature_cols = [
                'price_to_bb_middle', 'dist_upper_norm', 'dist_lower_norm',
                'bb_width', 'rsi', 'volatility', 'returns_std',
                'high_low_ratio', 'close_open_ratio',
                'sma_5', 'sma_20', 'sma_50'
            ]
            
            # é›¢æ£„æˆ– nan æ•¸æ“š
            X = df[feature_cols].fillna(method='ffill').fillna(method='bfill')
            y = df['bb_touch_label']
            
            # 5. åˆ†å‰²è¨“ç·´/æ¸¬è©¦é›†
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42, stratify=y
            )
            
            print(f'  è¨“ç·´é›†: {len(X_train)} æ ¹')
            print(f'  æ¸¬è©¦é›†: {len(X_test)} æ ¹')
            
            # 6. è¨“ç·´æ¨¡å‹
            print(f'ğŸ“š è¨“ç·´æ¨¡å‹...')
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # æ¨™ç±¤è½‰æ›: -1 -> 0, 0 -> 1, 1 -> 2
            y_train_mapped = np.array([self.label_map[int(label)] for label in y_train])
            y_test_mapped = np.array([self.label_map[int(label)] for label in y_test])
            
            model = XGBClassifier(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                eval_metric='mlogloss',
                verbosity=0,
                num_class=3
            )
            
            model.fit(X_train_scaled, y_train_mapped)
            
            # 7. çµ±è¨ˆé‚Ÿè¨“ç·´é›†ç²¾æº–åº¦
            y_train_pred = model.predict(X_train_scaled)
            train_acc = accuracy_score(y_train_mapped, y_train_pred)
            
            # 8. çµ±è¨ˆæ¸¬è©¦é›†ç²¾æº–åº¦
            y_test_pred = model.predict(X_test_scaled)
            test_acc = accuracy_score(y_test_mapped, y_test_pred)
            test_f1 = f1_score(y_test_mapped, y_test_pred, average='weighted')
            
            # 9. æ¤œæŸ¥éæ“šåˆä½
            overfitting_status = self.check_overfitting(train_acc, test_acc)
            
            # 10. è½‰é¿éæ“šåˆä½ï¼Œåªé¡¯ç¤ºæ¸¬è©¦ç²¾æº–åº¦
            print(f'\nğŸ“ˆ ä¸»è¦æŒ‡æ¨™ï¼š')
            print(f'  æ¸¬è©¦ç²¾æº–åº¦: {test_acc:.4f} ({test_acc*100:.2f}%)')
            print(f'  æ¸¬è©¦ F1 åˆ†æ•¸: {test_f1:.4f}')
            
            print(f'\nåˆ†é¡å ±å‘Šï¼š')
            label_names = ['ä¸‹è»Œæ”¯æ’', 'ä¸­è»¸ä¸­ç«‹', 'ä¸Šè»Œé˜»åŠ›']
            print(classification_report(y_test_mapped, y_test_pred, target_names=label_names))
            
            # 11. ä¿å­˜æ¨¡å‹
            symbol_dir = self.models_base_dir / symbol / timeframe
            symbol_dir.mkdir(parents=True, exist_ok=True)
            
            model_path = symbol_dir / 'model.pkl'
            scaler_path = symbol_dir / 'scaler.pkl'
            label_map_path = symbol_dir / 'label_map.pkl'
            
            joblib.dump(model, model_path)
            joblib.dump(scaler, scaler_path)
            joblib.dump(self.label_map, label_map_path)
            
            print(f'\nğŸ“¦ æ¨¡å‹å·²ä¿å­˜:')
            print(f'  {model_path}')
            print(f'  {scaler_path}')
            print(f'  {label_map_path}')
            
            # å¦‚æœæœ‰ä¸¥é‡éæ“šåˆä½ï¼Œå‚³å› False ä»¥è·Ÿè¹¤
            return overfitting_status != 'bad'
        
        except Exception as e:
            print(f'âŒ è¨“ç·´å¤±æ•—: {e}')
            import traceback
            traceback.print_exc()
            return False
    
    def run_full_pipeline(self, touch_range=0.02, test_size=0.2):
        """
        ç‚ºæ‰€æœ‰å¹£ç¨® + timeframe è¨“ç·´æ¨¡å‹
        """
        print('\nğŸš€ é–‹å§‹ç‚ºæ‰€æœ‰å¹£ç¨®è¨“ç·´æ¨¡å‹...')
        
        success_count = 0
        warning_count = 0
        total_count = len(self.loader.symbols) * len(self.loader.timeframes)
        
        for symbol in self.loader.symbols:
            for timeframe in self.loader.timeframes:
                if self.train_single_symbol(symbol, timeframe, touch_range, test_size):
                    success_count += 1
        
        separator = '='*60
        print(f'\n{separator}')
        print(f'âœ… è¨“ç·´å®Œæˆï¼æˆåŠŸ: {success_count}/{total_count}')
        print(f'{separator}')
        print(f'æ¨¡å‹ä¿å­˜ä½ç½®: {self.models_base_dir}')
        print(f'çµæ§‹ï¼šmodels/bb_models/<SYMBOL>/<TIMEFRAME>/')


if __name__ == '__main__':
    trainer = BBModelTrainer()
    trainer.run_full_pipeline(touch_range=0.02, test_size=0.2)
