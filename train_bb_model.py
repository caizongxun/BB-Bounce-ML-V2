import pandas as pd
import numpy as np
from pathlib import Path
import joblib
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
from xgboost import XGBClassifier
import warnings

warnings.filterwarnings('ignore')

from data_loader import CryptoDataLoader
from label_generator import LabelGenerator

class BBModelTrainer:
    def __init__(self, output_dir='models'):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.loader = CryptoDataLoader()
        self.generator = LabelGenerator(period=20, std_dev=2)
        
        self.model = None
        self.scaler = None
    
    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        å¾ž K ç·šæ•¸æ“šè£½ä½œç‰¹å½•
        """
        df = df.copy()
        close_col = 'close' if 'close' in df.columns else 'Close'
        
        # åŸºç¤Ž OHLCV
        if 'open' not in df.columns and 'Open' in df.columns:
            df['open'] = df['Open']
            df['high'] = df['High']
            df['low'] = df['Low']
        
        # 1. åƒ¹æ ¼ä½ç½®ï¼ˆç›¸å°æ–¼ BB ä¸­è»¸ï¼‰
        df['price_to_bb_middle'] = (df[close_col] - df['bb_middle']) / df['bb_middle']
        
        # 2. åƒ¹æ ¼è·é›¢ä¸Š/ä¸‹è»Œ
        df['dist_upper_norm'] = (df['bb_upper'] - df[close_col]) / (df['bb_upper'] - df['bb_lower'])
        df['dist_lower_norm'] = (df[close_col] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])
        
        # 3. BB å¯¶äºˆï¼ˆBBW: Bollinger Bands Widthï¼‰
        df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle']
        
        # 4. RSI
        df = self.calculate_rsi(df)
        
        # 5. å‹˜å‹•æ€§
        df['volatility'] = df['volatility'].fillna(df['volatility'].mean())
        
        # 6. åƒ¹æ ¼å‹•åŸ¸ï¼ˆæ—¥å¹¾ä½•å¹£çŽ‡ï¼‰
        df['returns'] = df[close_col].pct_change()
        df['returns_std'] = df['returns'].rolling(window=20).std()
        
        # 7. åƒ¹æ ¼è·‘å‹¢
        df['high_low_ratio'] = df['high'] / df['low'] - 1 if 'high' in df.columns else 0
        df['close_open_ratio'] = df[close_col] / df['open'] - 1 if 'open' in df.columns else 0
        
        # 8. ç§»å‹•å¹³å‡
        df['sma_5'] = df[close_col].rolling(window=5).mean()
        df['sma_20'] = df[close_col].rolling(window=20).mean()
        df['sma_50'] = df[close_col].rolling(window=50).mean()
        
        # æ¨£å­æ“šæ²™æ­£è¨¼åŒ–
        df = df.fillna(method='bfill').fillna(method='ffill')
        
        return df
    
    def calculate_rsi(self, df: pd.DataFrame, period=14) -> pd.DataFrame:
        """
        è¨ˆç®— RSI (Relative Strength Index)
        """
        df = df.copy()
        close_col = 'close' if 'close' in df.columns else 'Close'
        
        delta = df[close_col].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        df['rsi'] = df['rsi'].fillna(50)
        
        return df
    
    def load_and_prepare_data(self, touch_range=0.02):
        """
        è¼‰å…¥æ•´ç†æ•´å€‹è¨“ç·´æ•¸æ“šé›†
        """
        print('ðŸš€ é–‹å§‹ä¸‹è¼‰ 22 ç¨®å¹£ç¨®çš„æ•´å€‹è¨“ç·´æ•¸æ“šé§•...')
        
        all_dfs = []
        
        for symbol in self.loader.symbols:
            try:
                print(f'  â¬‡ï¸  {symbol}...', end=' ', flush=True)
                
                # ä¸‹è¼‰æ‰€æœ‰ timeframe
                symbol_dfs = []
                for tf in self.loader.timeframes:
                    df = self.loader.download_symbol_data(symbol, tf)
                    if df is not None:
                        # ç”¢ç”Ÿæ¨™ç±¤
                        df = self.generator.create_training_dataset(df, lookahead=5, touch_range=touch_range)
                        df['symbol'] = symbol
                        df['timeframe'] = tf
                        symbol_dfs.append(df)
                
                if symbol_dfs:
                    combined = pd.concat(symbol_dfs, ignore_index=True)
                    all_dfs.append(combined)
                    print(f'âœ… {len(combined)} æ ¹')
                else:
                    print(f'âŒ')
            
            except Exception as e:
                print(f'âŒ {e}')
        
        # æ•´åˆæ‰€æœ‰è¨“ç·´æ•¸æ“š
        if all_dfs:
            full_df = pd.concat(all_dfs, ignore_index=True)
            print(f'\nâœ… æ•´åˆå¾Œ: {len(full_df)} æ ¹è¨“ç·´æ•¸æ“š')
            return full_df
        else:
            raise ValueError('æ²’æœ‰æˆåŠŸåŠ è¼‰ä»»ä½•è¨“ç·´æ•¸æ“š')
    
    def train(self, X_train, y_train, X_test=None, y_test=None):
        """
        è¨“ç·´ XGBClassifier
        """
        print(f'\nðŸ“š è¨“ç·´ BB æ¨™ç±¤åˆ†é¡žå™¨...')
        
        # æ–°å»¶ä¼¸åŒ–
        self.scaler = StandardScaler()
        X_train_scaled = self.scaler.fit_transform(X_train)
        
        # è¨“ç·´æ¨¡å¼
        self.model = XGBClassifier(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            eval_metric='mlogloss',
            verbosity=0
        )
        
        self.model.fit(X_train_scaled, y_train)
        
        # é©—è­‰
        if X_test is not None and y_test is not None:
            X_test_scaled = self.scaler.transform(X_test)
            y_pred = self.model.predict(X_test_scaled)
            
            acc = accuracy_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred, average='weighted')
            
            print(f'  ä¸Šä½œ: {acc:.4f}')
            print(f'  F1 åˆ†æ•¸: {f1:.4f}')
            print(f'\nç®•ç§‘é –æˆ¶è™Ÿè¾²è±¡ï¼š')
            print(classification_report(y_test, y_pred, target_names=['ä¸‹è»Œ', 'ä¸­é–“', 'ä¸Šè»Œ']))
    
    def save_model(self):
        """
        ä¿å­˜æ¨¡å¼
        """
        model_path = self.output_dir / 'bb_model.pkl'
        scaler_path = self.output_dir / 'bb_scaler.pkl'
        
        joblib.dump(self.model, model_path)
        joblib.dump(self.scaler, scaler_path)
        
        print(f'\nðŸ’¾ æ¨¡å¼å·²ä¿å­˜:')
        print(f'  {model_path}')
        print(f'  {scaler_path}')
    
    def run_full_pipeline(self, touch_range=0.02, test_size=0.2):
        """
        åŸ·è¡Œå®Œæ•´è¨“ç·´æµç¨‹
        """
        # 1. åŠ è¼‰æ•´ç†æ•¸æ“š
        df = self.load_and_prepare_data(touch_range=touch_range)
        
        # 2. ç”¢ç”¢ç‰¹å½›
        print(f'\nðŸ”§ ç”¢ç”¢ç‰¹å½•...')
        df = self.create_features(df)
        
        # 3. æ²é¸ç‰¹å½›
        feature_cols = [
            'price_to_bb_middle', 'dist_upper_norm', 'dist_lower_norm',
            'bb_width', 'rsi', 'volatility', 'returns_std',
            'high_low_ratio', 'close_open_ratio',
            'sma_5', 'sma_20', 'sma_50'
        ]
        
        # ç¦»é¸“æˆ– nan æ•¸æ“š
        X = df[feature_cols].fillna(method='ffill').fillna(method='bfill')
        y = df['bb_touch_label']
        
        # 4. å‚³åˆ†è¨“ç·´/æ¸¬è©¦é›†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )
        
        print(f'  è¨“ç·´é›†: {len(X_train)} æ ¹')
        print(f'  æ¸¬è©¦é›†: {len(X_test)} æ ¹')
        
        # 5. è¨“ç·´æ¨¡å¼
        self.train(X_train.values, y_train.values, X_test.values, y_test.values)
        
        # 6. ä¿å­˜æ¨¡å¼
        self.save_model()
        
        print(f'\nâœ… è¨“ç·´å®Œæˆï¼')


if __name__ == '__main__':
    trainer = BBModelTrainer()
    trainer.run_full_pipeline(touch_range=0.02, test_size=0.2)
